# AIFFEL Project
매주 화, 목 프로젝트 진행
---

## [E01] RockPaperScissor : 가위바위보 이미지 분류기 만들기
#### [루브릭]
	이미지 분류기 모델이 성공적으로 만들어졌는가? - 트레이닝이 정상적으로 수행되었음
	오버피팅을 극복하기 위한 적절한 시도가 있었는가? - 데이터셋의 다양성, 정규화 등의 시도가 적절하였음
	분류모델의 test accuracy가 기준 이상 높게 나왔는가? - 60% 이상 도달하였음
### [모델 만들기]
1. 필요한 라이브러리 설치
2. 데이터 불러오기 및 resizing
3. 딥러닝 네트워크 설계
4. 딥러닝 네트워크 학습시키기
5. 얼마나 잘 만들었는지 확인하기 (test)
#### [Overfitting 극복하기]
1. 데이터 다양성 높이기 : 300개 -> 3300개 train set 형성하기
2. 정규화(Regularization)
	* 하이퍼파라미터를 변형해서 모델 복잡도 줄이기
		* epoch를 제외한 나머지 3개 하이퍼파라미터의 경우의 수 확인
		* 적절한 epoch 선택하기 (early stop)
	* validation set으로 k-fold cross validation
	* learning rate를 높여주기
	* 드롭아웃(drop out)
#### [결론 및 회고]

---

## [E02] Iris :
### (1) load_digits : 손글씨를 분류해 봅시다
### (2) load_wine : 와인을 분류해 봅시다
### (3) load_breast_cancer : 유방암 여부를 진단해 봅시다 
#### [루브릭]
1. 3가지 데이터셋의 구성이 합리적으로 진행되었는가? - feature와 label 선정을 위한 데이터 분석과정이 체계적으로 전개됨
2. 3가지 데이터셋에 대해 각각 5가지 모델을 성공적으로 적용하였는가? - 모델학습 및 테스트가 정상적으로 수행되었음
3. 3가지 데이터셋에 대해 모델의 평가지표가 적절히 선택되었는가?- 평가지표 선택 및 이유 설명이 타당함
#### [학습 과정]
1. 필요한 모듈 import 하기
2. 데이터 준비
3. 데이터 이해하기
	* feature, label 선정을 위한 데이터 분석 과정
4. train, test 데이터 분리
5. 다양한 모델로 학습시키기
	* Decision Tree
	* Random Forest
	* SVM
	* SGD Classifier
	* Logistic Regression
6. 각각의 모델 평가하기
#### [결론 및 회고]

---

## [E03] Camera Sticker : 고양이 수염 스티커 만들기
#### [루브릭]
1. 자기만의 카메라앱 기능 구현을 완수하였다.
	* 원본에 스티커 사진이 정상적으로 합성되었다.
2. 스티커 이미지를 정확한 원본 위치에 반영하였다.
	* 정확한 좌표계산을 통해 고양이 수염의 위치가 원본 얼굴에 잘 어울리게 출력되었다.
3. 카메라 스티커앱을 다양한 원본이미지에 적용했을 때의 문제점을 체계적으로 분석하였다.
	* 얼굴각도, 이미지 밝기, 촬영거리 등 다양한 변수에 따른 영향도를 보고서에 체계적으로 분석하였다.
#### [학습 과정]
1. 스티커 구하기 or 만들기
2. 얼굴 검출 & 랜드마크 검출 하기
3. 스티커 적용 위치 확인하기
4. 스티커 적용하기
5. 문제점 찾아보기
#### [결과 및 회고]

---

## [E04] Sentiment Analysis : 네이버 영화 리뷰 감성 분석 도전하기
#### [루브릭]
1. 다양한 방법으로 Text Classification 태스크를 성공적으로 구현하였다.
	* 3가지 이상의 모델이 성공적으로 시도됨
2. gensim을 활용하여 자체학습된 혹은 사전학습된 임베딩 레이어를 분석하였다.
	* gensim의 유사단어 찾기를 활용하여 자체학습한 임베딩과 사전학습 임베딩을 적절히 분석함
3. 한국어 Word2Vec을 활용하여 가시적인 성능향상을 달성했다.
	* 네이버 영화리뷰 데이터 감성분석 정확도를 85% 이상 달성함
#### [학습 과정]
1) 데이터 준비와 확인
2) 데이터로더 구성
3) 모델구성을 위한 데이터 분석 및 가공
4) 모델 구성 및 validation set 구성
5) 모델 훈련 개시
6) Loss Accuracy 그래프 시각화
7) 학습된 Embedding 레이어 분석
8) 한국어 Word2Vec 임베딩 활용하여 성능 개선
#### [결과 및 회고]

---

## [E05] Speech To Text : Spectrogram Calssification 모델 구현하기
#### [루브릭]
1. 음성데이터를 2차원 Spectrogram 으로 변환하여 데이터셋을 구성하였다.
	* 스펙트로그램 시각화 및 train/test 데이터셋 구성이 정상진행되었다.
2. 1,2차원 데이터를 처리하는 음성인식 모델이 정상 작동한다.
	* 스펙트로그램을 입력받은 모델이 학습과정에서 안정적으로 수렴하며, evaluation/test 단계를 무리없이 진행가능하다.
3. 테스트셋 수행결과 음성인식 모델의 Accuracy가 일정 수준에 도달하였다.
	* evaluation 결과 75% 이상의 정확도를 달성하는 모델이 하나 이상 존재한다.
#### [학습 과정]
1. 데이터 처리와 분류
2. 학습을 위한 하이퍼파라미터 설정
3. 데이터셋 구성
4. 2차원 Spectrogram 데이터를 처리하는 모델 구성
5. 학습 후, 학습이 어떻게 진행됐는지 그래프로 출력
6. Test dataset을 이용해서 모델의 성능을 평가
#### [결론 및 회고]

---

## [E06] Lyricist AI : 멋진 작사가 만들기
#### [루브릭]
1. 가사 텍스트 생성 모델이 정상적으로 동작하는가?
	* 텍스트 제너레이션 결과가 그럴듯한 문장으로 생성되는가?
2. 데이터의 전처리와 데이터셋 구성 과정이 체계적으로 진행되었는가?
	* 특수문자 제거, 토크나이저 생성, 패딩처리 등의 과정이 빠짐없이 진행되었는가?
3. 텍스트 생성모델이 안정적으로 학습되었는가?
	* 텍스트 생성모델의 validation loss가 2.2 이하로 낮아졌는가?
#### [학습 과정]
1. 데이터 다운로드
2. 데이터 읽어오기
3. 데이터 정제
4. 평가 데이터셋 분리
5. 인공지능 만들기
#### [결과 및 회고]

---

## [E07] Face Embedding : 나랑 닮은 연예인을 찾아보자
#### [루브릭]
1. 얼굴임베딩 벡터를 활용해 가장 닮은 연예인 Best 5를 구할 수 있다.
	* 닮은꼴 순위, 이름, 임베딩 거리를 포함한 Top-5 리스트가 정렬되어 출력되었다.
2. 충분한 수의 이미지에 대한 시도를 통해 매우 닮은꼴의 연예인을 찾아냈다.
	* 다양한 탐색을 통해 본인과 임베딩 거리 0.5 이내로 닮은 연예인을 찾아냈다.
3. 다양하고 재미있는 결과 시각화를 시도하였다.
	* matplotlib 등 다양한 시각화 도구를 하나 이상 이용해 재미있는 결과 시각화를 구현하였다.
#### [학습과정]
1. 사진 모으기
	* 내 사진 찍기
	* 비교할 연예인 사진 모으기
2. 얼굴 영역 자르기
3. 얼굴 영역의 임베딩 추출하기
4. 모은 연예인들과 비교하기
5. 다양한 재미있는 시각화 시도해보기
#### [결론 및 회고]

---

## [E08] Recommendation Music : Movielens 영화 추천 실습
#### [루브릭]
1. CSR matrix가 정상적으로 만들어졌다.
	* 사용자와 아이템 개수를 바탕으로 정확한 사이즈로 만들었다.
2. MF 모델이 정상적으로 훈련되어 그럴듯한 추천이 이루어졌다.
	* 사용자와 아이템 벡터 내적수치가 의미있게 형성되었다.
3. 비슷한 영화 찾기와 유저에게 추천하기의 과정이 정상적으로 진행되었다.
	* MF모델이 예측한 유저 선호도 및 아이템간 유사도, 기여도가 의미있게 측정되었다.
#### [학습 과정]
1. 데이터 준비와 전처리
2. 분석해 봅시다
	* ratings에 있는 유니크한 영화 개수
	* rating에 있는 유니크한 사용자 수
	* 가장 인기 있는 영화 30개(인기순)
3. 내가 선호하는 영화를 5가지 골라서 rating에 추가해 줍시다.
4. CSR matrix를 직접 만들어 봅시다.
5. als_model = AlternatingLeastSquares 모델을 직접 구성하여 훈련시켜 봅시다.
6. 내가 선호하는 5가지 영화 중 하나와 그 외의 영화 하나를 골라 훈련된 모델이 예측한 나의 선호도를 파악해 보세요.
7. 내가 좋아하는 영화와 비슷한 영화를 추천받아 봅시다.
8. 내가 가장 좋아할 만한 영화들을 추천받아 봅시다.
#### [결론 및 회고]

---

## [E09] Kaggle- 2019kaKr Housing : This is your playground! Leaderboard 정복하기
#### 2019 2nd ML month with KaKR : House Price Prediction
#### [루브릭]
1. 캐글 데이터분석 전과정이 성공적으로 진행되었는가?
	* 데이터 전처리, 모델학습, 예측의 전체 과정을 거쳐 캐글 submission까지 진행되었다.
2. 전처리, 학습과정 및 결과에 대한 설명이 시각화를 포함하여 체계적으로 진행되었는가?
	* 제출된 노트북이 캐글 커널로 사용될 수 있을 만큼 전처리, 학습, 최적화 진행 과정이 체계적으로 기술되었다.
3. 회귀모델 예측정확도가 기준 이상 높게 나왔는가?
	* 다양한 피처 엔지니어링과 하이퍼 파라미터 튜닝 등의 최적화 기법을 통해 캐글 리더보드의 Private score 기준 110000 이하의 점수를 얻었다.
#### [학습과정]
1. 데이터 살펴보기
2. 데이터 시각화
3. 데이터 전처리
4. 모델링
5. 결과 분석
#### [결론 및 회고]

---

## [E10] Human Segmentation : 인물 모드 문제점 찾기
#### [루브릭]
1. 인물모드 사진을 성공적으로 제작하였다.
	* 아웃포커싱 효과가 적용된 본인의 인물모드 사진과 고양이 사진, 배경전환 크로마키사진을 각각 1장 이상 성공적으로 제작하였다.
2. 제작한 인물모드 사진들에서 나타나는 문제점을 정확히 지적하였다.
	* 인물사진에서 발생한 문제점을 정확히 지적한 사진을 제출하였다.
3. 인물모드 사진의 문제점을 개선할 수 있는 솔루션을 적절히 제시하였다.
	* 추가적인 depth 정보를 활용하여 semantic segmentation mask의 오류를 보완할 수 있는 좋은 솔루션을 구체적으로 제시하였다.
#### [학습 과정]
1. 인물모드 직접 해 보기
	* 최소 3장 이상의 인물 사진모드 
	* 인물뿐만 아니라 다른 피사체에 대한 아웃포커싱 사진 만들기
	* 배경사진을 다른 이미지로 교체하는 크로마키 배경 합성 시도하기
2. 사진에서 문제점 찾기
3. 해결 방법을 제안해 보기
#### [결론 및 회고]

---

## [E11] Text Summarization : 뉴스 기사 요약해보기
#### [루브릭]
1. Abstractive 모델 구성을 위한 텍스트 전처리 단계가 체계적으로 진행되었다.
	* 분석단계, 정제단계, 정규화와 불용어 제거, 데이터셋 분리, 인코딩 과정이 빠짐없이 체계적으로 진행되었다.
2. 텍스트 요약모델이 성공적으로 학습되었음을 확인하였다.
	* 모델학습이 안정적으로 수렴되었음을 그래프를 통해 확인하였으며, 실제 요약문과 유사한 요약문장을 얻을 수 있었다.
3. Extractive 요약을 시도해 보고 Abstractive 요약 결과과 함께 비교해 보았다.
	* 두 요약 결과를 문법완성도 측면과 핵심단어 포함 측면으로 나누어 비교분석 결과를 제시하였다.
#### [학습과정]
1. 데이터 수집하기
2. 데이터 전처리하기(추상적 요약)
3. 어텐션 메커니즘 사용하기 (추상적 요약)
4. 실제 결과와 요약문 비교하기 (추상적 요약)
5. Summa을 이용해서 추출적 요약해보기
#### [결론 및 회고]

--- 

## [E12] Make New Fashion GAN : CIFAR-10 이미지 생성하기
#### [루브릭]
1. GAN의 두 모델 구조를 통해 이미지를 성공적으로 생성하였다.
	* 오브젝트 종류를 육안으로 구별할 수 있을 만한 이미지를 생성하였다.
2. 생성 이미지 시각화 및 학습 그래프를 통해 GAN 학습이 바르게 진행되었음을 입증하였다.
	* gif를 통해 생성이미지 품질이 서서히 향상되는 것과, fake accuracy가 추세적으로 0.5를 향해 하향하고 있음을 확인하였다.
3. 추가적인 GAN 모델구조 혹은 학습과정 개선 아이디어를 제안하고 이를 적용하였다.
	* 제출 아이디어를 제출 프로젝트에 반영하고, 그 결과가 아이디어 적용 이전보다 향상되었음을 시각적으로 입증하였다.
#### [학습과정]
1. 작업환경 구성하기
2. 데이터셋 구성하기
3. 생성자 모델 구현하기
4. 판별자 모델 구현하기
5. 손실함수와 최적화 함수 구현하기
6. 훈련과정 상세 기능 구현하기
7. 학습 과정 진행하기
8. (optional) GAN 훈련 과정 개선하기
#### [결론 및 회고]

---

## [E13] Time Series Prediction : 주식 예측에 도전해보자
#### [루브릭]
1. 시계열의 안정성이 충분히 확인되었는가?
	* 플로팅과 adfuller 메소드가 모두 적절히 사용되었음
2. ARIMA 모델 모수선택 근거를 체계적으로 제시하였는가?
	* p,q를 위한 ACF, PACF 사용과 d를 위한 차분 과정이 명확히 제시됨
3. 예측 모델의 오차율이 기준 이하로 정확하게 나왔는가?
	* 3개 이상 종목이 MAPE 10% 미만의 정확도로 예측됨
#### [학습과정]
1. 시계열 데이터 준비
2. 각종 전처리 수행
3. 시계열 안정성 분석
4. 학습, 테스트 데이터셋 생성
5. 적정 ARIMA 모수 찾기
6. ARIMA 모델 훈련과 테스트
7. 다른 주식 종목 예측해 보기
#### [결론 및 회고]

---

## [E14] Chatbot Transformer : 한국어 데이터로 챗봇 만들기
#### [루브릭]
1. 한국어 전처리를 통해 학습 데이터셋을 구축하였다.
	* 공백과 특수문자 처리, 토크나이징, 병렬데이터 구축의 과정이 적절히 진행되었다.
2. 트랜스포머 모델을 구현하여 한국어 챗봇 모델 학습을 정상적으로 진행하였다.
	* 구현한 트랜스포머 모델이 한국어 병렬 데이터 학습 시 안정적으로 수렴하였다.
3. 한국어 입력문장에 대해 한국어로 답변하는 함수를 구현하였다.
	* 한국어 입력문장에 그럴듯한 한국어로 답변을 리턴하였다.
#### [학습과정]
1. 데이터 수집하기
2. 데이터 전처리하기
3. SubwordTextEncoder 사용하기
4. 모델 구성하기
5. 모델 평가하기
#### [결론 및 회고]

---

## [E16] Super Resolution : SRGAN 활용하기
#### [루브릭]
1. SRGAN을 이용해 고해상도의 이미지를 생성하였다.
	* SRGAN을 통해 생성된 이미지를 제출하였다.
2. 다양한 해상도의 이미지에 대해 시각화를 통해 원본, SRGAN생성본, interpolation생성본을 비교분석하였다.
	* 이미지의 특성과 super resolution 방법을 관련지어 생성 결과를 체계적으로 분석하였다.
3. 저해상도 gif 동영상을 고해상도 동영상으로 성공적으로 변환하였다.
	* 저해상도 원본 gif와 생성된 고해상도 gif의 해상도 차이가 시각적으로 확인 가능하다.
#### [학습과정]
##### 프로젝트 1 : 직접 고른 이미지로 SRGAN 실험하기
* 프로젝트 1-1.
	1. (적당히) 높은 해상도를 가진 이미지를 검색해서 한 장 고른 후 저장하고 불러옵니다.
	2. 불러온 이미지에 bicubic interpolation을 적용해 가로 및 세로 픽셀 수를 1/4로 줄입니다. cv2.resize()를 사용해 봅시다.
	3. 줄인 저해상도 이미지를 입력으로 SRGAN을 이용해 고해상도 이미지를 생성합니다. 이전에 사용한 apply_srgan 함수를 사용하면 쉽습니다.
	4. 2.의 이미지에 bicubic interpolation을 적용해 가로 및 세로 픽셀 수를 다시 4배로 늘립니다. 마찬가지로 cv2.resize()를 사용해 봅시다.
	5. 3개 이미지(4.의 Bicubic의 결과, 3.의 SRGAN의 결과, 1.의 원래 고해상도 이미지)를 나란히 시각화합니다. 각 이미지의 제목에 어떤 방법에 대한 결과인지 표시해 주세요. 이전 시각화에 사용했던 코드를 참고하면 어렵지 않습니다.
	6. 선택한 이미지를 DIV2K 데이터셋에서 학습된 모델로 Super Resolution했을 때 어떠한 결과가 나왔으며, 왜 이러한 결과가 출력되었는지 설명해 봅시다. (정답은 없습니다)

* 프로젝트 1-2.
	1. (적당히) 낮은 해상도를 가진 이미지를 검색해서 한 장 고른 후 저장하고 불러옵니다.
	2. 불러온 이미지를 입력으로 SRGAN을 이용해 고해상도 이미지를 생성합니다. 이전에 사용한 apply_srgan 함수를 사용하면 쉽습니다.
	3. 1.에서 불러온 이미지에 bicubic interpolation을 적용해 가로 및 세로 픽셀 수를 다시 4배로 늘립니다. cv2.resize()를 사용해 봅시다.
	4. 2개 이미지(3.의 Bicubic의 결과, 2.의 SRGAN의 결과)를 나란히 시각화합니다. 각 이미지의 제목에 어떤 방법에 대한 결과인지 표시해 주세요. 이전 시각화에 사용했던 코드를 참고하면 어렵지 않습니다.
	5. 선택한 이미지를 DIV2K 데이터셋에서 학습된 모델로 Super Resolution했을 때 어떠한 결과가 나왔으며, 왜 이러한 결과가 출력되었는지 설명해 봅시다. (정답은 없습니다)

##### 프로젝트 2 : SRGAN을 이용해 고해상도 gif 생성하기
	1. gif 파일 불러오기
	2. 프레임별 Super Resolution 진행하기
	3. 프레임을 합쳐 gif 만들기
	4. Jupyter notebook에 gif 표시하기
#### [결론 및 회고]

---

## [E17] Session Based Recommendation : Movielens 영화 SBR
#### [루브릭]
1. Movielens 데이터셋을 session based recommendation 관점으로 전처리하는 과정이 체계적으로 진행되었다.
	* 데이터셋의 면밀한 분석을 토대로 세션단위 정의 과정(길이분석, 시간분석)을 합리적으로 수행한 과정이 기술되었다.
2. RNN 기반의 예측 모델이 정상적으로 구성되어 안정적으로 훈련이 진행되었다.
	* 적절한 epoch만큼의 학습이 진행되는 과정에서 train loss가 안정적으로 감소하고, validation 단계에서의 Recall, MRR이 개선되는 것이 확인된다.
3. 세션정의, 모델구조, 하이퍼파라미터 등을 변경해서 실험하여 Recall, MRR 등의 변화추이를 관찰하였다.
	* 3가지 이상의 변화를 시도하고 그 실험결과를 체계적으로 분석하였다.
#### [학습과정]
1. 데이터의 전처리
2. 미니 배치의 구성
3. 모델 구성
4. 모델 학습
5. 모델 테스트
#### [결론 및 회고]

---

## [E18] OCR : 다양한 OCR 모델 비교하기
#### [루브릭]
1. OCR을 활용하여 구현하려는 서비스의 기획이 타당한가?
	* 목표로 하는 서비스가 OCR를 적용 가능하며, OCR을 활용했을 때 더욱 유용해진다.
2. 모델 평가기준이 명확하고 체계적으로 세워졌는가?
	* 평가 기준에 부합하는 테스트 데이터의 특징이 무엇인지 명확하게 제시되었다.
3. 평가기준에 따라 충분한 분량의 테스트가 진행되고 그 결과가 잘 정리되었는가?
	* 최대 20장까지의 테스트 이미지를 사용해 제시된 평가 기준에 따른 테스트 결과가 잘 정리되어 결론이 도출되었다.
#### [학습과정]
1. 검증용 데이터셋 준비
2. Google OCR API, keras-ocr, Tesseract로 테스트 진행
3. 테스트 결과 정리
4. 결과 분석과 결론 제시
#### [결론 및 회고]

---

## [E19]
