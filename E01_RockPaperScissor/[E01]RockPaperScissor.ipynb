{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-7. 프로젝트: 가위바위보 분류기 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 필요한 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /home/ssac18/anaconda3/envs/aiffel/lib/python3.7/site-packages (8.0.1)\n",
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "# PIL 라이브러리가 설치되어 있지 않다면 설치\n",
    "!pip install pillow   \n",
    "\n",
    "from PIL import Image            # 이미지 불러오는 라이브러리\n",
    "import os, glob\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 불러오기 및 resizing   \n",
    "__가위 데이터 읽어와서 resizing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/ssac18/aiffel/E01_RockPaperScissor/train/scissor\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/E01_RockPaperScissor/train/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__바위 데이터 읽어와서 resizing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로: /home/ssac18/aiffel/E01_RockPaperScissor/train/rock\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# [[YOUR CODE]]\n",
    "image_dir_path = os.getenv(\"HOME\")+\"/aiffel/E01_RockPaperScissor/train/rock\"\n",
    "print(\"이미지 디렉토리 경로:\", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "# [[YOUR CODE]]\n",
    "target_size = (28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "    \n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__보 데이터 읽어와서 resizing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로: /home/ssac18/aiffel/E01_RockPaperScissor/train/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# [[YOUR CODE]]\n",
    "image_dir_path = os.getenv(\"HOME\")+\"/aiffel/E01_RockPaperScissor/train/paper\"\n",
    "print(\"이미지 디렉토리 경로:\", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "# [[YOUR CODE]]\n",
    "target_size = (28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "    \n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__load_data() 함수로 데이터 가져오기__  \n",
    "* X_train, y_train 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 3300 입니다.\n",
      "x_train shape: (3600, 28, 28, 3)\n",
      "y_train shape: (3600,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=3600   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "    \n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "        \n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/E01_RockPaperScissor/train\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0])     # 잘 불러오는지 확인\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 딥러닝 네트워크 설계하기  \n",
    "__최적의 하이퍼파라미터찾기__\n",
    "\n",
    "우선, 저는 적당히 큰 임의의 수를 하이퍼파라미터로 지정한 뒤 모델을 돌렸습니다. 각각 64, 128, 64의 값을 주었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                204864    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 280,707\n",
      "Trainable params: 280,707\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "# [[YOUR CODE]]\n",
    "hp_1 = 64\n",
    "hp_2 = 128\n",
    "dense = 64\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(hp_1, (3,3), activation='relu', input_shape=(28,28,3))) # 컬러 이미지이므로 1 아니고 3\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(hp_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax')) # 가위, 바위, 보 -> 3개 클래스로 분류\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 딥러닝 네트워크 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "113/113 [==============================] - 3s 28ms/step - loss: 0.9376 - accuracy: 0.5289\n",
      "Epoch 2/16\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.5863 - accuracy: 0.7567\n",
      "Epoch 3/16\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8631\n",
      "Epoch 4/16\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.9083\n",
      "Epoch 5/16\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1724 - accuracy: 0.9358\n",
      "Epoch 6/16\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1347 - accuracy: 0.9558\n",
      "Epoch 7/16\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0852 - accuracy: 0.9750\n",
      "Epoch 8/16\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0672 - accuracy: 0.9822\n",
      "Epoch 9/16\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0469 - accuracy: 0.9892\n",
      "Epoch 10/16\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9911\n",
      "Epoch 11/16\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 0.9928\n",
      "Epoch 12/16\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0236 - accuracy: 0.9936\n",
      "Epoch 13/16\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0122 - accuracy: 0.9983\n",
      "Epoch 14/16\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 0.9981\n",
      "Epoch 15/16\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 0.9978\n",
      "Epoch 16/16\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 0.9997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6aa820b2d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.compile()과 model.fit()을 사용해 봅시다.\n",
    "# [[YOUR CODE]]\n",
    "epoch = 16\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs= epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 얼마나 잘 만들었는지 확인하기(테스트)\n",
    "\n",
    "__테스트 데이터셋 만들기__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/ssac18/aiffel/E01_RockPaperScissor/rock_scissor_paper_2/scissor\n",
      "이미지 디렉토리 경로: /home/ssac18/aiffel/E01_RockPaperScissor/rock_scissor_paper_2/rock\n",
      "이미지 디렉토리 경로: /home/ssac18/aiffel/E01_RockPaperScissor/rock_scissor_paper_2/paper\n",
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (3600, 28, 28, 3)\n",
      "y_test shape: (3600,)\n"
     ]
    }
   ],
   "source": [
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "# [[YOUR CODE]]\n",
    "#test 데이터 가위 resizing\n",
    "image_dir_path_01 = os.getenv(\"HOME\") + \"/aiffel/E01_RockPaperScissor/rock_scissor_paper_2/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path_01)\n",
    "\n",
    "images=glob.glob(image_dir_path_01 + \"/*.jpg\")  \n",
    "\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "#test 데이터 바위 resizing\n",
    "image_dir_path_02 = os.getenv(\"HOME\")+\"/aiffel/E01_RockPaperScissor/rock_scissor_paper_2/rock\"\n",
    "print(\"이미지 디렉토리 경로:\", image_dir_path_02)\n",
    "\n",
    "images=glob.glob(image_dir_path_02 + \"/*.jpg\")\n",
    "target_size = (28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "# test 데이터 보 resizing\n",
    "image_dir_path_03 = os.getenv(\"HOME\")+\"/aiffel/E01_RockPaperScissor/rock_scissor_paper_2/paper\"\n",
    "print(\"이미지 디렉토리 경로:\", image_dir_path_03)\n",
    "\n",
    "images=glob.glob(image_dir_path_03 + \"/*.jpg\")\n",
    "\n",
    "target_size = (28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "  \n",
    "  ###########################################\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/E01_RockPaperScissor/rock_scissor_paper_2\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__예측하기__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 0s - loss: 0.2830 - accuracy: 0.9506\n",
      "test_loss :0.2830098867416382 \n",
      "test_accuracy: 0.9505555629730225\n"
     ]
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.evaluate()을 사용해 봅시다.\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose= 2)\n",
    "print(\"test_loss :{} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정확도가 95%가 나왔습니다. 예측의 정확도가 높으니 매우 좋은 모델입니다.  \n",
    "그렇지만 다른 하이퍼파라미터 값을 넣었을 때 어떻게 변화하는지 살펴보겠습니다.  \n",
    "우선, 3개의 하이퍼파라미터 값들이 대체로 낮거나 높은 경우 어떤 것이 더 좋은 모델인지 확인해보려 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최적의 하이퍼파라미터를 찾는 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함수 만들기..?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_train(hp_1,hp_2):\n",
    "#    hp_1 = [16, 32, 64, 128]                모든 하이퍼파라미터를 함수에 넣고 돌리려고 시도하다가 컴퓨터가 터질뻔 했습니다.\n",
    "#    hp_2 = [16]\n",
    "    dense = [16, 32, 64, 128]\n",
    "    \n",
    "    models = []\n",
    "    info = []\n",
    "    \n",
    "#     for i in hp_1:\n",
    "    \n",
    "#     for j in hp_2:\n",
    "    for k in dense:\n",
    "        model = keras.models.Sequential()\n",
    "        model.add(keras.layers.Conv2D(hp_1, (3,3), activation='relu', input_shape=(28,28,3))) # 컬러 이미지이므로 1 아니고 3\n",
    "        model.add(keras.layers.MaxPool2D(2,2))\n",
    "        model.add(keras.layers.Conv2D(hp_2, (3,3), activation='relu'))\n",
    "        model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "        model.add(keras.layers.Flatten())\n",
    "        model.add(keras.layers.Dense(k, activation='relu'))\n",
    "        model.add(keras.layers.Dense(3, activation='softmax')) # 가위, 바위, 보 -> 3개 클래스로 분류\n",
    "\n",
    "        models.append(model)    # 모델을 배열에 저장하기\n",
    "        info.append(str(k))\n",
    "#                model.summary()\n",
    "\n",
    "    \n",
    "    epoch = 20\n",
    "    index = 0\n",
    "    \n",
    "    for model in models:\n",
    "        print(\"--------------------------------------------------------------------------------------\")\n",
    "        print(\"models[\",index ,\"] : \", hp_1, \"/\", hp_2, \"/\", info[index], \"- hp_1/hp_2/dense\" )\n",
    "        model.compile(optimizer = 'adam',\n",
    "                      loss = 'sparse_categorical_crossentropy',\n",
    "                      metrics = ['accuracy'])\n",
    "\n",
    "        model.fit(x_train_norm, y_train, epochs= epoch)\n",
    "        index = index + 1\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------\n",
      "models[ 0 ] :  16 / 16 / 16 - hp_1/hp_2/dense\n",
      "Epoch 1/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 1.0458 - accuracy: 0.4864\n",
      "Epoch 2/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.8556 - accuracy: 0.6031\n",
      "Epoch 3/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.7214 - accuracy: 0.6981\n",
      "Epoch 4/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6252 - accuracy: 0.7483\n",
      "Epoch 5/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5567 - accuracy: 0.7792\n",
      "Epoch 6/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.4881 - accuracy: 0.8114\n",
      "Epoch 7/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.4184 - accuracy: 0.8508\n",
      "Epoch 8/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.3886 - accuracy: 0.8628\n",
      "Epoch 9/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.3430 - accuracy: 0.8786\n",
      "Epoch 10/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2980 - accuracy: 0.8964\n",
      "Epoch 11/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2716 - accuracy: 0.9144\n",
      "Epoch 12/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2548 - accuracy: 0.9056\n",
      "Epoch 13/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2279 - accuracy: 0.9219\n",
      "Epoch 14/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2213 - accuracy: 0.9253\n",
      "Epoch 15/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1873 - accuracy: 0.9422\n",
      "Epoch 16/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1810 - accuracy: 0.9419\n",
      "Epoch 17/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1622 - accuracy: 0.9483\n",
      "Epoch 18/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1549 - accuracy: 0.9514\n",
      "Epoch 19/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1413 - accuracy: 0.9569\n",
      "Epoch 20/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1281 - accuracy: 0.9578\n",
      "--------------------------------------------------------------------------------------\n",
      "models[ 1 ] :  16 / 16 / 32 - hp_1/hp_2/dense\n",
      "Epoch 1/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.0410 - accuracy: 0.4717\n",
      "Epoch 2/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.8509 - accuracy: 0.6058\n",
      "Epoch 3/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.6669 - accuracy: 0.7197\n",
      "Epoch 4/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.8022\n",
      "Epoch 5/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3846 - accuracy: 0.8544\n",
      "Epoch 6/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2997 - accuracy: 0.8936\n",
      "Epoch 7/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2425 - accuracy: 0.9169\n",
      "Epoch 8/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2037 - accuracy: 0.9294\n",
      "Epoch 9/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1732 - accuracy: 0.9403\n",
      "Epoch 10/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1530 - accuracy: 0.9508\n",
      "Epoch 11/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1369 - accuracy: 0.9572\n",
      "Epoch 12/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1197 - accuracy: 0.9631\n",
      "Epoch 13/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1213 - accuracy: 0.9619\n",
      "Epoch 14/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0913 - accuracy: 0.9719\n",
      "Epoch 15/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0806 - accuracy: 0.9761\n",
      "Epoch 16/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0709 - accuracy: 0.9792\n",
      "Epoch 17/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.0633 - accuracy: 0.9842\n",
      "Epoch 18/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.0775 - accuracy: 0.9767\n",
      "Epoch 19/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.9889\n",
      "Epoch 20/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.0460 - accuracy: 0.9872\n",
      "--------------------------------------------------------------------------------------\n",
      "models[ 2 ] :  16 / 16 / 64 - hp_1/hp_2/dense\n",
      "Epoch 1/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 1.0366 - accuracy: 0.4375\n",
      "Epoch 2/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.8980 - accuracy: 0.5575\n",
      "Epoch 3/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.7036 - accuracy: 0.6925\n",
      "Epoch 4/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5477 - accuracy: 0.7839\n",
      "Epoch 5/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.4108 - accuracy: 0.8444\n",
      "Epoch 6/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.3264 - accuracy: 0.8781\n",
      "Epoch 7/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2609 - accuracy: 0.8994\n",
      "Epoch 8/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2072 - accuracy: 0.9256\n",
      "Epoch 9/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1764 - accuracy: 0.9386\n",
      "Epoch 10/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1403 - accuracy: 0.9544\n",
      "Epoch 11/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1335 - accuracy: 0.9528\n",
      "Epoch 12/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1136 - accuracy: 0.9606\n",
      "Epoch 13/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.0853 - accuracy: 0.9744\n",
      "Epoch 14/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.0779 - accuracy: 0.9742\n",
      "Epoch 15/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.0703 - accuracy: 0.9800\n",
      "Epoch 16/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.0614 - accuracy: 0.9844\n",
      "Epoch 17/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.0528 - accuracy: 0.9847\n",
      "Epoch 18/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.0807 - accuracy: 0.9756\n",
      "Epoch 19/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.0445 - accuracy: 0.9886\n",
      "Epoch 20/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.0322 - accuracy: 0.9936\n",
      "--------------------------------------------------------------------------------------\n",
      "models[ 3 ] :  16 / 16 / 128 - hp_1/hp_2/dense\n",
      "Epoch 1/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.9907 - accuracy: 0.4725\n",
      "Epoch 2/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.7651 - accuracy: 0.6603\n",
      "Epoch 3/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5805 - accuracy: 0.7589\n",
      "Epoch 4/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4023 - accuracy: 0.8531\n",
      "Epoch 5/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.3098 - accuracy: 0.8892\n",
      "Epoch 6/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2435 - accuracy: 0.9175\n",
      "Epoch 7/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2019 - accuracy: 0.9272\n",
      "Epoch 8/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1574 - accuracy: 0.9467\n",
      "Epoch 9/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1249 - accuracy: 0.9622\n",
      "Epoch 10/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1159 - accuracy: 0.9603\n",
      "Epoch 11/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.0924 - accuracy: 0.9681\n",
      "Epoch 12/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.0726 - accuracy: 0.9772\n",
      "Epoch 13/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0637 - accuracy: 0.9833\n",
      "Epoch 14/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.0521 - accuracy: 0.9836\n",
      "Epoch 15/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.0468 - accuracy: 0.9875\n",
      "Epoch 16/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0339 - accuracy: 0.9922\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 0s 1ms/step - loss: 0.0319 - accuracy: 0.9931\n",
      "Epoch 18/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.0358 - accuracy: 0.9892\n",
      "Epoch 19/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.0397 - accuracy: 0.9906\n",
      "Epoch 20/20\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.0189 - accuracy: 0.9958\n"
     ]
    }
   ],
   "source": [
    "auto_train(16,16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 중 가장 좋은 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_train(16,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_train(16,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_train(16,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_train(32,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_train(32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_train(32,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_train(32,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_train(64,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_train(64,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_train(64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_train(64,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_train(128,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_train(128,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_train(128,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_train(128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최적의 에포크 찾는 과정은 무엇이었는가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.9153 - accuracy: 0.5456\n",
      "Epoch 2/16\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.5583 - accuracy: 0.7672\n",
      "Epoch 3/16\n",
      "113/113 [==============================] - 2s 15ms/step - loss: 0.3381 - accuracy: 0.8689\n",
      "Epoch 4/16\n",
      "113/113 [==============================] - 4s 38ms/step - loss: 0.2267 - accuracy: 0.9117\n",
      "Epoch 5/16\n",
      "113/113 [==============================] - 2s 15ms/step - loss: 0.1626 - accuracy: 0.9403\n",
      "Epoch 6/16\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.1240 - accuracy: 0.9567\n",
      "Epoch 7/16\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.0996 - accuracy: 0.9678\n",
      "Epoch 8/16\n",
      "113/113 [==============================] - 3s 26ms/step - loss: 0.0631 - accuracy: 0.9808\n",
      "Epoch 9/16\n",
      "113/113 [==============================] - 3s 29ms/step - loss: 0.0558 - accuracy: 0.9844\n",
      "Epoch 10/16\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.0410 - accuracy: 0.9897\n",
      "Epoch 11/16\n",
      "113/113 [==============================] - 4s 38ms/step - loss: 0.0402 - accuracy: 0.9892\n",
      "Epoch 12/16\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 0.0180 - accuracy: 0.9953\n",
      "Epoch 13/16\n",
      "113/113 [==============================] - 3s 26ms/step - loss: 0.0134 - accuracy: 0.9978\n",
      "Epoch 14/16\n",
      "113/113 [==============================] - 3s 29ms/step - loss: 0.0724 - accuracy: 0.9789\n",
      "Epoch 15/16\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.0421 - accuracy: 0.9875\n",
      "Epoch 16/16\n",
      "113/113 [==============================] - 2s 21ms/step - loss: 0.0114 - accuracy: 0.9981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5b40a57cd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.compile()과 model.fit()을 사용해 봅시다.\n",
    "# [[YOUR CODE]]\n",
    "epoch = 16\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs= epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/ssac18/aiffel/E01_RockPaperScissor/rock_scissor_paper_2/scissor\n",
      "이미지 디렉토리 경로: /home/ssac18/aiffel/E01_RockPaperScissor/rock_scissor_paper_2/rock\n",
      "이미지 디렉토리 경로: /home/ssac18/aiffel/E01_RockPaperScissor/rock_scissor_paper_2/paper\n",
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (3600, 28, 28, 3)\n",
      "y_test shape: (3600,)\n"
     ]
    }
   ],
   "source": [
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "# [[YOUR CODE]]\n",
    "#test 데이터 가위 resizing\n",
    "image_dir_path_01 = os.getenv(\"HOME\") + \"/aiffel/E01_RockPaperScissor/rock_scissor_paper_2/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path_01)\n",
    "\n",
    "images=glob.glob(image_dir_path_01 + \"/*.jpg\")  \n",
    "\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "#test 데이터 바위 resizing\n",
    "image_dir_path_02 = os.getenv(\"HOME\")+\"/aiffel/E01_RockPaperScissor/rock_scissor_paper_2/rock\"\n",
    "print(\"이미지 디렉토리 경로:\", image_dir_path_02)\n",
    "\n",
    "images=glob.glob(image_dir_path_02 + \"/*.jpg\")\n",
    "target_size = (28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "# test 데이터 보 resizing\n",
    "image_dir_path_03 = os.getenv(\"HOME\")+\"/aiffel/E01_RockPaperScissor/rock_scissor_paper_2/paper\"\n",
    "print(\"이미지 디렉토리 경로:\", image_dir_path_03)\n",
    "\n",
    "images=glob.glob(image_dir_path_03 + \"/*.jpg\")\n",
    "\n",
    "target_size = (28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "  \n",
    "  ###########################################\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/E01_RockPaperScissor/rock_scissor_paper_2\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 1s - loss: 0.3685 - accuracy: 0.9528\n",
      "test_loss :0.3685218393802643 \n",
      "test_accuracy: 0.9527778029441833\n"
     ]
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.evaluate()을 사용해 봅시다.\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose= 2)\n",
    "print(\"test_loss :{} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "처음에 300개 데이터로 했던 것도 적어주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
