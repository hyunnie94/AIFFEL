{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-7. 프로젝트: 가위바위보 분류기 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [루브릭]\n",
    "\n",
    "아래의 기준을 바탕으로 프로젝트를 평가합니다.\n",
    "\n",
    "평가문항\t상세기준  \n",
    "1. 이미지 분류기 모델이 성공적으로 만들어졌는가? - 트레이닝이 정상적으로 수행되었음  \n",
    "2. 오버피팅을 극복하기 위한 적절한 시도가 있었는가? - 데이터셋의 다양성, 정규화 등의 시도가 적절하였음  \n",
    "3. 분류모델의 test accuracy가 기준 이상 높게 나왔는가?  - 60% 이상 도달하였음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [모델 만들기]  \n",
    " 1. 필요한 라이브러리 설치\n",
    " 2. 데이터 불러오기 및 resizing\n",
    " 3. 딥러닝 네트워크 설계\n",
    " 4. 딥러닝 네트워크 학습시키기\n",
    " 5. 얼마나 잘 만들었는지 확인하기 (test)\n",
    "\n",
    "### [Overfitting 극복하기]\n",
    " 1. 데이터 다양성 높이기   \n",
    "     : 300개 -> 3300개 train set 형성하기\n",
    "     \n",
    " 2. 정규화(Regularization) \n",
    "     - 하이퍼파라미터를 변형해서 모델 복잡도 줄이기  \n",
    "         - epoch를 제외한 나머지 3개 하이퍼파라미터의 경우의 수 확인  \n",
    "         - 적절한 epoch 선택하기 (early stop)  \n",
    "     - validation set으로 k-fold cross validation\n",
    "     - learning rate를 높여주기\n",
    "     - 드롭아웃(drop out)\n",
    "\n",
    "### [결론 및 회고]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 이미지 분류기 모델 만들기   \n",
    "### 1. 필요한 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /home/ssac18/anaconda3/envs/aiffel/lib/python3.7/site-packages (8.0.1)\n",
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "# PIL 라이브러리가 설치되어 있지 않다면 설치\n",
    "!pip install pillow   \n",
    "\n",
    "from PIL import Image            # 이미지 불러오는 라이브러리\n",
    "import os, glob\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 불러오기 및 resizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__train 데이터 300개 resizing__  \n",
    "가위, 바위, 보 각각 100장씩 있음\n",
    "모든 파일의 사이즈를 28x28로 바꾸어서 저장해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/ssac18/aiffel/E01_RockPaperScissor/rock_scissor_paper/scissor\n",
      "가위 이미지 resize 완료!\n",
      "이미지 디렉토리 경로: /home/ssac18/aiffel/E01_RockPaperScissor/rock_scissor_paper/rock\n",
      "바위 이미지 resize 완료!\n",
      "이미지 디렉토리 경로: /home/ssac18/aiffel/E01_RockPaperScissor/rock_scissor_paper/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/E01_RockPaperScissor/rock_scissor_paper/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# [[YOUR CODE]]\n",
    "image_dir_path = os.getenv(\"HOME\")+\"/aiffel/E01_RockPaperScissor/rock_scissor_paper/rock\"\n",
    "print(\"이미지 디렉토리 경로:\", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "# [[YOUR CODE]]\n",
    "target_size = (28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "    \n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# [[YOUR CODE]]\n",
    "image_dir_path = os.getenv(\"HOME\")+\"/aiffel/E01_RockPaperScissor/rock_scissor_paper/paper\"\n",
    "print(\"이미지 디렉토리 경로:\", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "# [[YOUR CODE]]\n",
    "target_size = (28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "    \n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__load_data() 함수로 데이터 가져오기__  \n",
    "\n",
    "load data 함수란?\n",
    "(데이터 수, 28, 28, 컬러) 형태의 배열로 X_train 셋을 만들고, 정답이 담긴 라벨 데이터를 y_train 셋으로 만들어주는 함수입니다.\n",
    "* X_train, y_train 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train shape: (300, 28, 28, 3)\n",
      "y_train shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=300   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "    \n",
    "    idx=0\n",
    "    # 가위 데이터 불러오기\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'): \n",
    "        img = np.array(Image.open(file),dtype=np.int32)      #x_train \n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0 으로 라벨링. y_train\n",
    "        idx=idx+1\n",
    "        \n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)      #x_train \n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1 으로 라벨링. y_train\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)     #x_train\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2 으로 라벨링. y_train\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/E01_RockPaperScissor/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0])     # 잘 불러오는지 확인\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 딥러닝 네트워크 설계하기  \n",
    "\n",
    "우선, 저는 적당한 임의의 값을 하이퍼파라미터로 지정한 뒤 모델을 돌렸습니다.  \n",
    "LMS 학습하면서 mnist 데이터셋에 대해 하이퍼파라미터를 적용할 때 64, 32 값을 주었을 때 가장 높은 정확도를 보였습니다.\n",
    "그래서 가위바위보 이미지 셋에서는 정확도가 어떻게 나타나는지 확인하기 위해 하이퍼파라미터를 64, 32, 32의 값으로 주었고, epoch=20을 설정하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_88 (Conv2D)           (None, 26, 26, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_88 (MaxPooling (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_89 (Conv2D)           (None, 11, 11, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_89 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_44 (Flatten)         (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 45,987\n",
      "Trainable params: 45,987\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "# [[YOUR CODE]]\n",
    "hp_1 = 64\n",
    "hp_2 = 32\n",
    "dense = 32\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(hp_1, (3,3), activation='relu', input_shape=(28,28,3))) # 컬러 이미지이므로 1 아니고 3\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(hp_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax')) # 가위, 바위, 보 -> 3개 클래스로 분류\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 딥러닝 네트워크 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.0676 - accuracy: 0.4042\n",
      "Epoch 2/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.8753 - accuracy: 0.5794\n",
      "Epoch 3/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.6782 - accuracy: 0.7186\n",
      "Epoch 4/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.8036\n",
      "Epoch 5/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.8311\n",
      "Epoch 6/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3413 - accuracy: 0.8750\n",
      "Epoch 7/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2867 - accuracy: 0.8942\n",
      "Epoch 8/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2358 - accuracy: 0.9175\n",
      "Epoch 9/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2121 - accuracy: 0.9250\n",
      "Epoch 10/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1619 - accuracy: 0.9475\n",
      "Epoch 11/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1329 - accuracy: 0.9583\n",
      "Epoch 12/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1134 - accuracy: 0.9692\n",
      "Epoch 13/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0874 - accuracy: 0.9794\n",
      "Epoch 14/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0889 - accuracy: 0.9756\n",
      "Epoch 15/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0625 - accuracy: 0.9864\n",
      "Epoch 16/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0682 - accuracy: 0.9836\n",
      "Epoch 17/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0719 - accuracy: 0.9781\n",
      "Epoch 18/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0413 - accuracy: 0.9894\n",
      "Epoch 19/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0384 - accuracy: 0.9908\n",
      "Epoch 20/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0335 - accuracy: 0.9936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2ec87b2bd0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.compile()과 model.fit()을 사용해 봅시다.\n",
    "# [[YOUR CODE]]\n",
    "epoch = 20\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs= epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 얼마나 잘 만들었는지 확인하기(테스트)\n",
    "\n",
    "__테스트 데이터셋 만들기__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/ssac18/aiffel/E01_RockPaperScissor/rock_scissor_paper_2/scissor\n",
      "가위 이미지 resize 완료!\n",
      "이미지 디렉토리 경로: /home/ssac18/aiffel/E01_RockPaperScissor/rock_scissor_paper_2/rock\n",
      "바위 이미지 resize 완료!\n",
      "이미지 디렉토리 경로: /home/ssac18/aiffel/E01_RockPaperScissor/rock_scissor_paper_2/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "# [[YOUR CODE]]\n",
    "#test 데이터 가위 resizing\n",
    "image_dir_path_01 = os.getenv(\"HOME\") + \"/aiffel/E01_RockPaperScissor/rock_scissor_paper_2/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path_01)\n",
    "\n",
    "images=glob.glob(image_dir_path_01 + \"/*.jpg\")  \n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "#test 데이터 바위 resizing\n",
    "image_dir_path_02 = os.getenv(\"HOME\")+\"/aiffel/E01_RockPaperScissor/rock_scissor_paper_2/rock\"\n",
    "print(\"이미지 디렉토리 경로:\", image_dir_path_02)\n",
    "\n",
    "images=glob.glob(image_dir_path_02 + \"/*.jpg\")\n",
    "target_size = (28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "# test 데이터 보 resizing\n",
    "image_dir_path_03 = os.getenv(\"HOME\")+\"/aiffel/E01_RockPaperScissor/rock_scissor_paper_2/paper\"\n",
    "print(\"이미지 디렉토리 경로:\", image_dir_path_03)\n",
    "\n",
    "images=glob.glob(image_dir_path_03 + \"/*.jpg\")\n",
    "target_size = (28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "print(\"보 이미지 resize 완료!\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__load_test_data() 함수로 데이터 가져오기__  \n",
    "\n",
    "load teset data 함수란?\n",
    "(데이터 수, 28, 28, 컬러) 형태의 배열로 X_test 셋을 만들고, 정답이 담긴 라벨 데이터를 y_test 셋으로 만들어주는 함수입니다.\n",
    "* X_test, y_test 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트데이터(x_test)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "def load_test_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=300   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "    \n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'): \n",
    "        img = np.array(Image.open(file),dtype=np.int32)      #X_test \n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0 으로 라벨링. y_test\n",
    "        idx=idx+1\n",
    "        \n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)      #x_test\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1 으로 라벨링. y_test\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)     #x_test\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2 으로 라벨링. y_test\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"테스트데이터(x_test)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/E01_RockPaperScissor/rock_scissor_paper_2\"\n",
    "(x_test, y_test)=load_test_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__예측하기__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 3.0689 - accuracy: 0.4500\n",
      "test_loss :3.068925380706787 \n",
      "test_accuracy: 0.44999998807907104\n"
     ]
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.evaluate()을 사용해 봅시다.\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose= 2)\n",
    "print(\"test_loss :{} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 정확도가  0.44999998807907104으로 생각보다 매우 낮은 수치입니다.  \n",
    "저는 다른 사람들이 slack에 업로드한 데이터 셋 3300개를 얻어 새로운 훈련셋을 만들 수 있었습니다.  \n",
    "위와 동일한 모델에 데이터 수만 변경하여 다시 성능을 확인하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Overfitting 극복하기(1) - 데이터 다양성 높혀서 모델 학습, 성능 테스트하기   \n",
    "\n",
    "slack에 올라온 다른 데이터 3300개를 추가적으로 합쳐서 3600개의 훈련셋을 만들어주었습니다.  \n",
    "아래의 코드에서 적용한 하이퍼파라미터들은 앞서 300개 데이터로 학습한 모델과 동일하게 설정해주었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/ssac18/aiffel/E01_RockPaperScissor/train/scissor\n",
      "가위 이미지 resize 완료!\n",
      "이미지 디렉토리 경로: /home/ssac18/aiffel/E01_RockPaperScissor/train/rock\n",
      "바위 이미지 resize 완료!\n",
      "이미지 디렉토리 경로: /home/ssac18/aiffel/E01_RockPaperScissor/train/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/E01_RockPaperScissor/train/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# [[YOUR CODE]]\n",
    "image_dir_path = os.getenv(\"HOME\")+\"/aiffel/E01_RockPaperScissor/train/rock\"\n",
    "print(\"이미지 디렉토리 경로:\", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "# [[YOUR CODE]]\n",
    "target_size = (28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "    \n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# [[YOUR CODE]]\n",
    "image_dir_path = os.getenv(\"HOME\")+\"/aiffel/E01_RockPaperScissor/train/paper\"\n",
    "print(\"이미지 디렉토리 경로:\", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "# [[YOUR CODE]]\n",
    "target_size = (28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "    \n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 3600 입니다.\n",
      "x_train shape: (3600, 28, 28, 3)\n",
      "y_train shape: (3600,)\n"
     ]
    }
   ],
   "source": [
    "def load_data_2(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=3600   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "    \n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'): \n",
    "        img = np.array(Image.open(file),dtype=np.int32)      #x_train \n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0 으로 라벨링. y_train\n",
    "        idx=idx+1\n",
    "        \n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)      #x_train \n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1 으로 라벨링. y_train\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)     #x_train\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2 으로 라벨링. y_train\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/E01_RockPaperScissor/train\"\n",
    "(x_train, y_train)=load_data_2(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0])     # 잘 불러오는지 확인\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_90 (Conv2D)           (None, 26, 26, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_90 (MaxPooling (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_91 (Conv2D)           (None, 11, 11, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_91 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_45 (Flatten)         (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 45,987\n",
      "Trainable params: 45,987\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hp_1 = 64\n",
    "hp_2 = 32\n",
    "dense = 32\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(hp_1, (3,3), activation='relu', input_shape=(28,28,3))) # 컬러 이미지이므로 1 아니고 3\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(hp_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax')) # 가위, 바위, 보 -> 3개 클래스로 분류\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트데이터(x_test)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/E01_RockPaperScissor/rock_scissor_paper_2\"\n",
    "(x_test, y_test)=load_test_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.0386 - accuracy: 0.4406\n",
      "Epoch 2/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.8214 - accuracy: 0.6292\n",
      "Epoch 3/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.5788 - accuracy: 0.7781\n",
      "Epoch 4/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.8311\n",
      "Epoch 5/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3500 - accuracy: 0.8700\n",
      "Epoch 6/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2862 - accuracy: 0.8917\n",
      "Epoch 7/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2404 - accuracy: 0.9139\n",
      "Epoch 8/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1912 - accuracy: 0.9314\n",
      "Epoch 9/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1557 - accuracy: 0.9489\n",
      "Epoch 10/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1305 - accuracy: 0.9542\n",
      "Epoch 11/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1080 - accuracy: 0.9653\n",
      "Epoch 12/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0861 - accuracy: 0.9758\n",
      "Epoch 13/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0718 - accuracy: 0.9783\n",
      "Epoch 14/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.9828\n",
      "Epoch 15/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0560 - accuracy: 0.9839\n",
      "Epoch 16/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0477 - accuracy: 0.9878\n",
      "Epoch 17/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0438 - accuracy: 0.9900\n",
      "Epoch 18/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 0.9942\n",
      "Epoch 19/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0223 - accuracy: 0.9958\n",
      "Epoch 20/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0207 - accuracy: 0.9967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2ee84cc310>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch = 20\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs= epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 2.7514 - accuracy: 0.5100\n",
      "test_loss :2.7514145374298096 \n",
      "test_accuracy: 0.5099999904632568\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose= 2)\n",
    "print(\"test_loss :{} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측확률분포: [1.45818403e-05 8.82570922e-01 1.17414415e-01]\n",
      "라벨: 2, 예측결과: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측확률분포: [1.3734499e-04 1.6791391e-01 8.3194870e-01]\n",
      "라벨: 0, 예측결과: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측확률분포: [5.4793258e-04 2.7206107e-03 9.9673152e-01]\n",
      "라벨: 0, 예측결과: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측확률분포: [9.681664e-02 9.292233e-08 9.031833e-01]\n",
      "라벨: 0, 예측결과: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측확률분포: [4.895183e-07 9.986633e-01 1.336236e-03]\n",
      "라벨: 2, 예측결과: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_result = model.predict(x_test_norm)\n",
    "predicted_labels = np.argmax(predicted_result, axis=1)\n",
    "\n",
    "import random\n",
    "wrong_predict_list=[]\n",
    "for i, _ in enumerate(predicted_labels):\n",
    "    # i번째 test_labels과 y_test이 다른 경우만 모아 봅시다. \n",
    "    if predicted_labels[i] != y_test[i]:\n",
    "        wrong_predict_list.append(i)\n",
    "\n",
    "# wrong_predict_list 에서 랜덤하게 5개만 뽑아봅시다.\n",
    "samples = random.choices(population=wrong_predict_list, k=5)\n",
    "\n",
    "for n in samples:\n",
    "    print(\"예측확률분포: \" + str(predicted_result[n]))\n",
    "    print(\"라벨: \" + str(y_test[n]) + \", 예측결과: \" + str(predicted_labels[n]))\n",
    "    plt.imshow(x_test[n], cmap=plt.cm.binary)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정확도가 0.5099999904632568가 나왔습니다. 이전 모델보다 약간 오르긴 했으나 그래도 작은 수치입니다.\n",
    "새로운 데이터에선 정확도가 떨어지는 과대적합을 최소화시키는 과정이 필요합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting 극복하기(2) -  Regularization\n",
    "\n",
    "모델이 과대적합되었을 가능성이 있습니다. 과대적합은 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할 때 발생합니다. 모델의 종류를 변경하지 않으면서 과대적합을 줄이기 위해 다음의 방법으로 모델을 수정하려 합니다.\n",
    "\n",
    "#### 1) 모델의 복잡도를 낮추기\n",
    "   -> 인공 신경망의 복잡도는 은닉층(hidden layer)의 수나 매개변수의 수 등으로 결정된다고 합니다. 우선, 저는 __하이퍼파라미터값을 변화__ 시키는 방법으로 은닉층의 변화를 주어서 모델의 복잡도를 줄이고자 합니다.   \n",
    "    \n",
    "#### 2) Regularization 층 적용하기\n",
    "   -> __Drop Out, L1 Regularization, Batch normalization__ 층을 각각 여러 형태로 추가하여 높은 정확도의 모델을 찾아냅니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 모델 수정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) 하이퍼 파라미터 적용하는 함수 만들기  \n",
    "하이퍼파라미터는 대체로 2의 제곱의 수로 지정해준다고 합니다. 따라서   \n",
    "hp_1  : [16, 32, 64]  \n",
    "hp_2  : [16, 32, 64]  \n",
    "dense : [16, 32, 64]  \n",
    "각각의 하이퍼파라미터들의 값이 될 수 있는 후보를 16에서 최대 64로 3개씩 지정해주고 모든 경우의 수를 고려해보려 합니다.  \n",
    "27번의 코드를 쓰는 것은 번거롭기 때문에 자동으로 학습해주는 함수를 만들어 그 결과를 보겠습니다.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_train(hp_1,hp_2):\n",
    "#    hp_1 = [16, 32, 64]                모든 하이퍼파라미터를 함수에 넣고 돌리려고 시도하다가 컴퓨터가 터질뻔 했습니다.\n",
    "#    hp_2 = [16, 32, 64]\n",
    "    dense = [16, 32, 64]    \n",
    "    models = []           # 모델을 담는 배열\n",
    "    info = []             # dense 배열의 index를 담는 배열\n",
    "    \n",
    "    \n",
    "#     for i in hp_1:\n",
    "    \n",
    "#     for j in hp_2:\n",
    "    for k in dense:\n",
    "        model = keras.models.Sequential()\n",
    "        model.add(keras.layers.Conv2D(hp_1, (3,3), activation='relu', input_shape=(28,28,3))) # 컬러 이미지이므로 1 아니고 3\n",
    "        model.add(keras.layers.MaxPool2D(2,2))\n",
    "        model.add(keras.layers.Conv2D(hp_2, (3,3), activation='relu'))\n",
    "        model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "        model.add(keras.layers.Flatten())\n",
    "        model.add(keras.layers.Dense(k, activation='relu'))\n",
    "        model.add(keras.layers.Dense(3, activation='softmax')) # 가위, 바위, 보 -> 3개 클래스로 분류\n",
    "        models.append(model)    # 모델을 배열에 저장하기\n",
    "        info.append(str(k))\n",
    "#       model.summary()\n",
    "\n",
    "    \n",
    "    epoch = 10\n",
    "    index = 0\n",
    "    \n",
    "    for model in models:\n",
    "        print(\"--------------------------------------------------------------------------------------\")\n",
    "        print(\"models[\",index ,\"] : \", hp_1, \"/\", hp_2, \"/\", info[index], \"- hp_1/hp_2/dense\" )\n",
    "        model.compile(optimizer = 'adam',\n",
    "                      loss = 'sparse_categorical_crossentropy',\n",
    "                      metrics = ['accuracy'])\n",
    "\n",
    "        model.fit(x_train_norm, y_train, epochs= epoch)\n",
    "        index = index + 1\n",
    "        \n",
    "        test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose= 2)\n",
    "        print(\"test_loss :{} \".format(test_loss))\n",
    "        print(\"test_accuracy: {}\".format(test_accuracy))\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "처음 코드를 만들 때 모든 하이퍼파라미터를 함수 안에 넣어서 돌리려 했으나, 컴퓨터가 터질뻔 했습니다...  \n",
    "그래서 2개의 하이퍼파라미터는 매개변수로 받는 것으로 함수를 수정한 뒤 9번 함수를 실행했습니다.  \n",
    "아래는 그 과정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------\n",
      "models[ 0 ] :  16 / 16 / 16 - hp_1/hp_2/dense\n",
      "Epoch 1/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 1.0700 - accuracy: 0.4144\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.9516 - accuracy: 0.5386\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.7947 - accuracy: 0.6483\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6460 - accuracy: 0.7383\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5429 - accuracy: 0.7744\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.8231\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.8419\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 0.8750\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8892\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2832 - accuracy: 0.8981\n",
      "10/10 - 0s - loss: 1.7504 - accuracy: 0.4067\n",
      "test_loss :1.7504241466522217 \n",
      "test_accuracy: 0.40666666626930237\n",
      "--------------------------------------------------------------------------------------\n",
      "models[ 1 ] :  16 / 16 / 32 - hp_1/hp_2/dense\n",
      "Epoch 1/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 1.0599 - accuracy: 0.4172\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.9478 - accuracy: 0.5408\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.7783 - accuracy: 0.6533\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6287 - accuracy: 0.7483\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5225 - accuracy: 0.7964\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.4368 - accuracy: 0.8311\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.3737 - accuracy: 0.8614\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.3397 - accuracy: 0.8739\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2972 - accuracy: 0.8908\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2666 - accuracy: 0.9017\n",
      "10/10 - 0s - loss: 1.3346 - accuracy: 0.4933\n",
      "test_loss :1.3345855474472046 \n",
      "test_accuracy: 0.4933333396911621\n",
      "--------------------------------------------------------------------------------------\n",
      "models[ 2 ] :  16 / 16 / 64 - hp_1/hp_2/dense\n",
      "Epoch 1/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 1.0483 - accuracy: 0.4525\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.8429 - accuracy: 0.6342\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6580 - accuracy: 0.7350\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.8147\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.8528\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.3249 - accuracy: 0.8908\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2710 - accuracy: 0.9103\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2310 - accuracy: 0.9219\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1928 - accuracy: 0.9372\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1614 - accuracy: 0.9450\n",
      "10/10 - 0s - loss: 2.4739 - accuracy: 0.4233\n",
      "test_loss :2.473923683166504 \n",
      "test_accuracy: 0.4233333468437195\n"
     ]
    }
   ],
   "source": [
    "auto_train(16,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------\n",
      "models[ 0 ] :  16 / 32 / 16 - hp_1/hp_2/dense\n",
      "Epoch 1/10\n",
      "113/113 [==============================] - 4s 35ms/step - loss: 1.0370 - accuracy: 0.4697\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.8365 - accuracy: 0.6367\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.6417 - accuracy: 0.7497\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.8272\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.3951 - accuracy: 0.8606\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.8906\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2704 - accuracy: 0.9094\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2248 - accuracy: 0.9261\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1992 - accuracy: 0.9339\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1641 - accuracy: 0.9525\n",
      "10/10 - 1s - loss: 1.5420 - accuracy: 0.4433\n",
      "test_loss :1.5419883728027344 \n",
      "test_accuracy: 0.44333332777023315\n",
      "--------------------------------------------------------------------------------------\n",
      "models[ 1 ] :  16 / 32 / 32 - hp_1/hp_2/dense\n",
      "Epoch 1/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 1.0557 - accuracy: 0.4419\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.8599 - accuracy: 0.6067\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.6313 - accuracy: 0.7481\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.4887 - accuracy: 0.8147\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.3976 - accuracy: 0.8528\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.3176 - accuracy: 0.8836\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2525 - accuracy: 0.9150\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2243 - accuracy: 0.9222\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1937 - accuracy: 0.9361\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1471 - accuracy: 0.9506\n",
      "10/10 - 0s - loss: 2.1939 - accuracy: 0.4467\n",
      "test_loss :2.193862199783325 \n",
      "test_accuracy: 0.4466666579246521\n",
      "--------------------------------------------------------------------------------------\n",
      "models[ 2 ] :  16 / 32 / 64 - hp_1/hp_2/dense\n",
      "Epoch 1/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 1.0224 - accuracy: 0.4761\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.8056 - accuracy: 0.6456\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5808 - accuracy: 0.7806\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.8506\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8806\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2549 - accuracy: 0.9097\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2156 - accuracy: 0.9236\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1641 - accuracy: 0.9425\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1310 - accuracy: 0.9625\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1110 - accuracy: 0.9675\n",
      "10/10 - 0s - loss: 1.2622 - accuracy: 0.5333\n",
      "test_loss :1.262226939201355 \n",
      "test_accuracy: 0.5333333611488342\n"
     ]
    }
   ],
   "source": [
    "auto_train(16,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------\n",
      "models[ 0 ] :  16 / 64 / 16 - hp_1/hp_2/dense\n",
      "Epoch 1/10\n",
      "113/113 [==============================] - 4s 33ms/step - loss: 1.0874 - accuracy: 0.3822\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.9736 - accuracy: 0.5253\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.8291 - accuracy: 0.6442\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6761 - accuracy: 0.7272\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5136 - accuracy: 0.8136\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.4080 - accuracy: 0.8608\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8878\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2675 - accuracy: 0.9133\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2400 - accuracy: 0.9217\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1892 - accuracy: 0.9400\n",
      "10/10 - 1s - loss: 1.4345 - accuracy: 0.4933\n",
      "test_loss :1.434508204460144 \n",
      "test_accuracy: 0.4933333396911621\n",
      "--------------------------------------------------------------------------------------\n",
      "models[ 1 ] :  16 / 64 / 32 - hp_1/hp_2/dense\n",
      "Epoch 1/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 1.0387 - accuracy: 0.4472\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.8061 - accuracy: 0.6492\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6063 - accuracy: 0.7617\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.4784 - accuracy: 0.8214\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.3654 - accuracy: 0.8744\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.8864\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.9194\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2288 - accuracy: 0.9206\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1728 - accuracy: 0.9458\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1311 - accuracy: 0.9642\n",
      "10/10 - 0s - loss: 1.1772 - accuracy: 0.5467\n",
      "test_loss :1.1772300004959106 \n",
      "test_accuracy: 0.54666668176651\n",
      "--------------------------------------------------------------------------------------\n",
      "models[ 2 ] :  16 / 64 / 64 - hp_1/hp_2/dense\n",
      "Epoch 1/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 1.0253 - accuracy: 0.4603\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.7345 - accuracy: 0.6922\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5310 - accuracy: 0.7975\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 0.8639\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3044 - accuracy: 0.8869\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2496 - accuracy: 0.9150\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1774 - accuracy: 0.9475\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1577 - accuracy: 0.9475\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1209 - accuracy: 0.9706\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0911 - accuracy: 0.9789\n",
      "10/10 - 0s - loss: 1.8338 - accuracy: 0.4200\n",
      "test_loss :1.8337675333023071 \n",
      "test_accuracy: 0.41999998688697815\n"
     ]
    }
   ],
   "source": [
    "auto_train(16,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------\n",
      "models[ 0 ] :  32 / 16 / 16 - hp_1/hp_2/dense\n",
      "Epoch 1/10\n",
      "113/113 [==============================] - 7s 58ms/step - loss: 1.0615 - accuracy: 0.4239\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.9401 - accuracy: 0.5414\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.8020 - accuracy: 0.6583\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6278 - accuracy: 0.7539\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5063 - accuracy: 0.8089\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.4313 - accuracy: 0.8428\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.3781 - accuracy: 0.8572\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.3028 - accuracy: 0.8975\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2652 - accuracy: 0.9092\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2136 - accuracy: 0.9289\n",
      "10/10 - 1s - loss: 1.8299 - accuracy: 0.4233\n",
      "test_loss :1.829938530921936 \n",
      "test_accuracy: 0.4233333468437195\n",
      "--------------------------------------------------------------------------------------\n",
      "models[ 1 ] :  32 / 16 / 32 - hp_1/hp_2/dense\n",
      "Epoch 1/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 1.0643 - accuracy: 0.4297\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.9051 - accuracy: 0.5722\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.7350 - accuracy: 0.6844\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5942 - accuracy: 0.7556\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.4832 - accuracy: 0.8067\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3829 - accuracy: 0.8575\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.3166 - accuracy: 0.8794\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2493 - accuracy: 0.9142\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2040 - accuracy: 0.9339\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1807 - accuracy: 0.9392\n",
      "10/10 - 0s - loss: 1.4205 - accuracy: 0.5033\n",
      "test_loss :1.4205247163772583 \n",
      "test_accuracy: 0.503333330154419\n",
      "--------------------------------------------------------------------------------------\n",
      "models[ 2 ] :  32 / 16 / 64 - hp_1/hp_2/dense\n",
      "Epoch 1/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 1.0657 - accuracy: 0.4314\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.8980 - accuracy: 0.5858\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6997 - accuracy: 0.7103\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.5388 - accuracy: 0.7858\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.8314\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8742\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2896 - accuracy: 0.8950\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2454 - accuracy: 0.9136\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2017 - accuracy: 0.9317\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1639 - accuracy: 0.9467\n",
      "10/10 - 0s - loss: 2.0940 - accuracy: 0.4633\n",
      "test_loss :2.0939528942108154 \n",
      "test_accuracy: 0.4633333384990692\n"
     ]
    }
   ],
   "source": [
    "auto_train(32,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------\n",
      "models[ 0 ] :  32 / 32 / 16 - hp_1/hp_2/dense\n",
      "Epoch 1/10\n",
      "113/113 [==============================] - 4s 33ms/step - loss: 1.0402 - accuracy: 0.4478\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.8316 - accuracy: 0.6225\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6766 - accuracy: 0.7133\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5154 - accuracy: 0.7994\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.4090 - accuracy: 0.8467\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8822\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2733 - accuracy: 0.9058\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2301 - accuracy: 0.9233\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1996 - accuracy: 0.9358\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1695 - accuracy: 0.9517\n",
      "10/10 - 1s - loss: 1.3696 - accuracy: 0.4700\n",
      "test_loss :1.3696340322494507 \n",
      "test_accuracy: 0.4699999988079071\n",
      "--------------------------------------------------------------------------------------\n",
      "models[ 1 ] :  32 / 32 / 32 - hp_1/hp_2/dense\n",
      "Epoch 1/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 1.0502 - accuracy: 0.4356\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.8752 - accuracy: 0.6008\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6737 - accuracy: 0.7228\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.4926 - accuracy: 0.8172\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.8547\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.3101 - accuracy: 0.8875\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2501 - accuracy: 0.9108\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2070 - accuracy: 0.9297\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1566 - accuracy: 0.9550\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1221 - accuracy: 0.9669\n",
      "10/10 - 0s - loss: 1.9554 - accuracy: 0.4600\n",
      "test_loss :1.9553806781768799 \n",
      "test_accuracy: 0.46000000834465027\n",
      "--------------------------------------------------------------------------------------\n",
      "models[ 2 ] :  32 / 32 / 64 - hp_1/hp_2/dense\n",
      "Epoch 1/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 1.0061 - accuracy: 0.4744\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.7564 - accuracy: 0.6739\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5574 - accuracy: 0.7844\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.4291 - accuracy: 0.8406\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.3393 - accuracy: 0.8700\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2556 - accuracy: 0.9083\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1947 - accuracy: 0.9342\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1641 - accuracy: 0.9439\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1320 - accuracy: 0.9572\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1121 - accuracy: 0.9667\n",
      "10/10 - 0s - loss: 1.8003 - accuracy: 0.4833\n",
      "test_loss :1.8003027439117432 \n",
      "test_accuracy: 0.4833333194255829\n"
     ]
    }
   ],
   "source": [
    "auto_train(32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------\n",
      "models[ 0 ] :  32 / 64 / 16 - hp_1/hp_2/dense\n",
      "Epoch 1/10\n",
      "113/113 [==============================] - 4s 35ms/step - loss: 1.0732 - accuracy: 0.3989\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.9170 - accuracy: 0.5669\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6821 - accuracy: 0.7225\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5042 - accuracy: 0.8000\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.3968 - accuracy: 0.8544\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.3364 - accuracy: 0.8786\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2637 - accuracy: 0.9064\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2209 - accuracy: 0.9256\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1911 - accuracy: 0.9364\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.9594\n",
      "10/10 - 0s - loss: 1.2204 - accuracy: 0.4933\n",
      "test_loss :1.2203943729400635 \n",
      "test_accuracy: 0.4933333396911621\n",
      "--------------------------------------------------------------------------------------\n",
      "models[ 1 ] :  32 / 64 / 32 - hp_1/hp_2/dense\n",
      "Epoch 1/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.0228 - accuracy: 0.4611\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.8003 - accuracy: 0.6422\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5717 - accuracy: 0.7731\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.4401 - accuracy: 0.8414\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.3332 - accuracy: 0.8836\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2656 - accuracy: 0.9100\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2267 - accuracy: 0.9225\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 0.9431\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1542 - accuracy: 0.9489\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1140 - accuracy: 0.9667\n",
      "10/10 - 0s - loss: 1.9857 - accuracy: 0.4500\n",
      "test_loss :1.985718011856079 \n",
      "test_accuracy: 0.44999998807907104\n",
      "--------------------------------------------------------------------------------------\n",
      "models[ 2 ] :  32 / 64 / 64 - hp_1/hp_2/dense\n",
      "Epoch 1/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.9766 - accuracy: 0.5056\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6608 - accuracy: 0.7317\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.4722 - accuracy: 0.8272\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.3394 - accuracy: 0.8794\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2555 - accuracy: 0.9142\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2001 - accuracy: 0.9275\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1538 - accuracy: 0.9508\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1088 - accuracy: 0.9689\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.0873 - accuracy: 0.9758\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.0762 - accuracy: 0.9789\n",
      "10/10 - 0s - loss: 2.2061 - accuracy: 0.4600\n",
      "test_loss :2.206149101257324 \n",
      "test_accuracy: 0.46000000834465027\n"
     ]
    }
   ],
   "source": [
    "auto_train(32,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------\n",
      "models[ 0 ] :  64 / 16 / 16 - hp_1/hp_2/dense\n",
      "Epoch 1/10\n",
      "113/113 [==============================] - 4s 34ms/step - loss: 1.0723 - accuracy: 0.4025\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.9212 - accuracy: 0.5583\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.7551 - accuracy: 0.6689\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.6238 - accuracy: 0.7414\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7886\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.8314\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3898 - accuracy: 0.8536\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3434 - accuracy: 0.8761\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2962 - accuracy: 0.8875\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.9142\n",
      "10/10 - 1s - loss: 2.1271 - accuracy: 0.3800\n",
      "test_loss :2.1270525455474854 \n",
      "test_accuracy: 0.3799999952316284\n",
      "--------------------------------------------------------------------------------------\n",
      "models[ 1 ] :  64 / 16 / 32 - hp_1/hp_2/dense\n",
      "Epoch 1/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.0645 - accuracy: 0.4142\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.8695 - accuracy: 0.5908\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.6961 - accuracy: 0.7111\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.5684 - accuracy: 0.7750\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.8106\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4035 - accuracy: 0.8511\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8736\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2933 - accuracy: 0.8906\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2423 - accuracy: 0.9142\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2112 - accuracy: 0.9219\n",
      "10/10 - 0s - loss: 1.6832 - accuracy: 0.5000\n",
      "test_loss :1.6832222938537598 \n",
      "test_accuracy: 0.5\n",
      "--------------------------------------------------------------------------------------\n",
      "models[ 2 ] :  64 / 16 / 64 - hp_1/hp_2/dense\n",
      "Epoch 1/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.0514 - accuracy: 0.4375\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.8632 - accuracy: 0.6014\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.6432 - accuracy: 0.7364\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.8047\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8581\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8872\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2652 - accuracy: 0.9028\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2031 - accuracy: 0.9278\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1673 - accuracy: 0.9403\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1434 - accuracy: 0.9547\n",
      "10/10 - 0s - loss: 2.1241 - accuracy: 0.5000\n",
      "test_loss :2.1241455078125 \n",
      "test_accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "auto_train(64,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------\n",
      "models[ 0 ] :  64 / 32 / 16 - hp_1/hp_2/dense\n",
      "Epoch 1/10\n",
      "113/113 [==============================] - 4s 34ms/step - loss: 1.0788 - accuracy: 0.3681\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.0072 - accuracy: 0.4986\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.9301 - accuracy: 0.5903\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.7342 - accuracy: 0.6761\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7811\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.8311\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8650\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3331 - accuracy: 0.8808\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2726 - accuracy: 0.9056\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2303 - accuracy: 0.9300\n",
      "10/10 - 1s - loss: 2.1011 - accuracy: 0.4067\n",
      "test_loss :2.101139545440674 \n",
      "test_accuracy: 0.40666666626930237\n",
      "--------------------------------------------------------------------------------------\n",
      "models[ 1 ] :  64 / 32 / 32 - hp_1/hp_2/dense\n",
      "Epoch 1/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.0640 - accuracy: 0.4222\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.9228 - accuracy: 0.5547\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.6864 - accuracy: 0.7231\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7964\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.8681\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2933 - accuracy: 0.9000\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.9131\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1840 - accuracy: 0.9417\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1536 - accuracy: 0.9478\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1261 - accuracy: 0.9589\n",
      "10/10 - 0s - loss: 2.5011 - accuracy: 0.4600\n",
      "test_loss :2.5011391639709473 \n",
      "test_accuracy: 0.46000000834465027\n",
      "--------------------------------------------------------------------------------------\n",
      "models[ 2 ] :  64 / 32 / 64 - hp_1/hp_2/dense\n",
      "Epoch 1/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.0437 - accuracy: 0.4506\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.8435 - accuracy: 0.6239\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.6047 - accuracy: 0.7592\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.8175\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3413 - accuracy: 0.8725\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2568 - accuracy: 0.9042\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2128 - accuracy: 0.9292\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1508 - accuracy: 0.9522\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1209 - accuracy: 0.9650\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1063 - accuracy: 0.9714\n",
      "10/10 - 0s - loss: 1.3009 - accuracy: 0.5933\n",
      "test_loss :1.3009157180786133 \n",
      "test_accuracy: 0.5933333039283752\n"
     ]
    }
   ],
   "source": [
    "auto_train(64,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------\n",
      "models[ 0 ] :  64 / 64 / 16 - hp_1/hp_2/dense\n",
      "Epoch 1/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.0426 - accuracy: 0.4550\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.8168 - accuracy: 0.6378\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.6158 - accuracy: 0.7531\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.8192\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8581\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3151 - accuracy: 0.8875\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.9211\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1948 - accuracy: 0.9403\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1771 - accuracy: 0.9456\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1342 - accuracy: 0.9589\n",
      "10/10 - 0s - loss: 1.4364 - accuracy: 0.4833\n",
      "test_loss :1.4363856315612793 \n",
      "test_accuracy: 0.4833333194255829\n",
      "--------------------------------------------------------------------------------------\n",
      "models[ 1 ] :  64 / 64 / 32 - hp_1/hp_2/dense\n",
      "Epoch 1/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.9954 - accuracy: 0.4956\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.7254 - accuracy: 0.6861\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.8150\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8667\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8869\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2364 - accuracy: 0.9236\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1731 - accuracy: 0.9453\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1563 - accuracy: 0.9514\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1149 - accuracy: 0.9697\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1036 - accuracy: 0.9728\n",
      "10/10 - 0s - loss: 1.6958 - accuracy: 0.5200\n",
      "test_loss :1.6957777738571167 \n",
      "test_accuracy: 0.5199999809265137\n",
      "--------------------------------------------------------------------------------------\n",
      "models[ 2 ] :  64 / 64 / 64 - hp_1/hp_2/dense\n",
      "Epoch 1/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.0358 - accuracy: 0.4506\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.7698 - accuracy: 0.6506\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.7725\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4008 - accuracy: 0.8608\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2961 - accuracy: 0.8942\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2073 - accuracy: 0.9342\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1686 - accuracy: 0.9433\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1289 - accuracy: 0.9608\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0999 - accuracy: 0.9731\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0815 - accuracy: 0.9756\n",
      "10/10 - 0s - loss: 1.8232 - accuracy: 0.4833\n",
      "test_loss :1.8231828212738037 \n",
      "test_accuracy: 0.4833333194255829\n"
     ]
    }
   ],
   "source": [
    "auto_train(64,64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결론:    \n",
    "models :  64 / 32 / 64 - hp_1/hp_2/dense  \n",
    "Epoch 1/10  \n",
    "113/113 [==============================] - 0s 2ms/step - loss: 1.0437 - accuracy: 0.4506  \n",
    "Epoch 2/10  \n",
    "113/113 [==============================] - 0s 2ms/step - loss: 0.8435 - accuracy: 0.6239  \n",
    "Epoch 3/10  \n",
    "113/113 [==============================] - 0s 2ms/step - loss: 0.6047 - accuracy: 0.7592  \n",
    "Epoch 4/10  \n",
    "113/113 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.8175  \n",
    "Epoch 5/10  \n",
    "113/113 [==============================] - 0s 2ms/step - loss: 0.3413 - accuracy: 0.8725  \n",
    "Epoch 6/10  \n",
    "113/113 [==============================] - 0s 2ms/step - loss: 0.2568 - accuracy: 0.9042  \n",
    "Epoch 7/10  \n",
    "113/113 [==============================] - 0s 2ms/step - loss: 0.2128 - accuracy: 0.9292  \n",
    "Epoch 8/10  \n",
    "113/113 [==============================] - 0s 2ms/step - loss: 0.1508 - accuracy: 0.9522  \n",
    "Epoch 9/10  \n",
    "113/113 [==============================] - 0s 2ms/step - loss: 0.1209 - accuracy: 0.9650  \n",
    "Epoch 10/10  \n",
    "113/113 [==============================] - 0s 2ms/step - loss: 0.1063 - accuracy: 0.9714  \n",
    "10/10 - 0s - loss: 1.3009 - accuracy: 0.5933  \n",
    "test_loss :1.3009157180786133   \n",
    "test_accuracy: 0.5933333039283752  \n",
    "  \n",
    "위의 모델이 가장 높은 정확도를 보이는 하이퍼파라미터 입니다.  \n",
    "test_loss :1.3009157180786133 , test_accuracy: 0.5933333039283752 까지 올릴 수 있었습니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Regularization 적용  \n",
    "\n",
    "Reularization을 적용하는 방법으로 Dropout 층, L1 Regularization 층, Batch Normalization 층을 각각 다양한 방법으로 추가해준 뒤 그 결과를 확인하려 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.0706 - accuracy: 0.4072\n",
      "Epoch 2/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.9005 - accuracy: 0.5644\n",
      "Epoch 3/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.7514 - accuracy: 0.6639\n",
      "Epoch 4/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.6561 - accuracy: 0.7139\n",
      "Epoch 5/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.5759 - accuracy: 0.7544\n",
      "Epoch 6/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7978\n",
      "Epoch 7/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.8147\n",
      "Epoch 8/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.8414\n",
      "Epoch 9/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8600\n",
      "Epoch 10/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3024 - accuracy: 0.8861\n",
      "Epoch 11/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2955 - accuracy: 0.8903\n",
      "Epoch 12/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2670 - accuracy: 0.8950\n",
      "Epoch 13/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2357 - accuracy: 0.9139\n",
      "Epoch 14/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2310 - accuracy: 0.9131\n",
      "Epoch 15/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1923 - accuracy: 0.9267\n",
      "Epoch 16/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1818 - accuracy: 0.9333\n",
      "Epoch 17/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.9308\n",
      "Epoch 18/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1606 - accuracy: 0.9453\n",
      "Epoch 19/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1560 - accuracy: 0.9497\n",
      "Epoch 20/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1314 - accuracy: 0.9553\n",
      "10/10 - 0s - loss: 1.9220 - accuracy: 0.5100\n",
      "test_loss :1.9219518899917603 \n",
      "test_accuracy: 0.5099999904632568\n"
     ]
    }
   ],
   "source": [
    "# 드롭 1번\n",
    "\n",
    "hp_1 = 64\n",
    "hp_2 = 32\n",
    "dense = 64\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(hp_1, (3,3), activation='relu', input_shape=(28,28,3))) # 컬러 이미지이므로 1 아니고 3\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(hp_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dropout(0.5)) # 드롭아웃 추가. 비율은 50%\n",
    "model.add(keras.layers.Dense(dense, activation='relu'))\n",
    "#model.add(keras.layers.Dropout(0.5)) # 드롭아웃 추가. 비율은 50%\n",
    "#model.add(keras.layers.Dense(32, kernel_regularizer='l1'))  # L1 정규화 적용\n",
    "#model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(3, activation='softmax')) # 가위, 바위, 보 -> 3개 클래스로 분류\n",
    "\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "epoch = 20\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs= epoch)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose= 2)\n",
    "print(\"test_loss :{} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 2.7771 - accuracy: 0.3875\n",
      "Epoch 2/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.4480 - accuracy: 0.4917\n",
      "Epoch 3/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.9801 - accuracy: 0.6097\n",
      "Epoch 4/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.8626 - accuracy: 0.6636\n",
      "Epoch 5/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.7794 - accuracy: 0.7050\n",
      "Epoch 6/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.7023 - accuracy: 0.7408\n",
      "Epoch 7/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.6702 - accuracy: 0.7469\n",
      "Epoch 8/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.6048 - accuracy: 0.7783\n",
      "Epoch 9/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.5735 - accuracy: 0.7969\n",
      "Epoch 10/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.8203\n",
      "Epoch 11/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.8286\n",
      "Epoch 12/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.8400\n",
      "Epoch 13/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.8533\n",
      "Epoch 14/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.8628\n",
      "Epoch 15/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.8644\n",
      "Epoch 16/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.8736\n",
      "Epoch 17/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8869\n",
      "Epoch 18/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8936\n",
      "Epoch 19/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3364 - accuracy: 0.8969\n",
      "Epoch 20/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.9036\n",
      "10/10 - 0s - loss: 1.2475 - accuracy: 0.6100\n",
      "test_loss :1.2475314140319824 \n",
      "test_accuracy: 0.6100000143051147\n"
     ]
    }
   ],
   "source": [
    "# 드롭 1번, l1 정규화\n",
    "\n",
    "\n",
    "hp_1 = 64\n",
    "hp_2 = 32\n",
    "dense = 64\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(hp_1, (3,3), activation='relu', input_shape=(28,28,3))) # 컬러 이미지이므로 1 아니고 3\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(hp_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dropout(0.5)) # 드롭아웃 추가. 비율은 50%\n",
    "model.add(keras.layers.Dense(dense, activation='relu'))\n",
    "#model.add(keras.layers.Dropout(0.5)) # 드롭아웃 추가. 비율은 50%\n",
    "model.add(keras.layers.Dense(32, kernel_regularizer='l1'))  # L1 정규화 적용\n",
    "#model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(3, activation='softmax')) # 가위, 바위, 보 -> 3개 클래스로 분류\n",
    "\n",
    "#model.summary()\n",
    "epoch = 20\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs= epoch)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose= 2)\n",
    "print(\"test_loss :{} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.2286 - accuracy: 0.3933\n",
      "Epoch 2/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.9560 - accuracy: 0.5331\n",
      "Epoch 3/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.7836 - accuracy: 0.6442\n",
      "Epoch 4/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.6529 - accuracy: 0.7125\n",
      "Epoch 5/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.5640 - accuracy: 0.7592\n",
      "Epoch 6/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.7964\n",
      "Epoch 7/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.8164\n",
      "Epoch 8/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3915 - accuracy: 0.8444\n",
      "Epoch 9/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3559 - accuracy: 0.8553\n",
      "Epoch 10/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2999 - accuracy: 0.8831\n",
      "Epoch 11/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3137 - accuracy: 0.8761\n",
      "Epoch 12/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2553 - accuracy: 0.9039\n",
      "Epoch 13/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2376 - accuracy: 0.9100\n",
      "Epoch 14/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2173 - accuracy: 0.9169\n",
      "Epoch 15/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2294 - accuracy: 0.9069\n",
      "Epoch 16/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2046 - accuracy: 0.9208\n",
      "Epoch 17/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2048 - accuracy: 0.9242\n",
      "Epoch 18/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1800 - accuracy: 0.9328\n",
      "Epoch 19/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.9397\n",
      "Epoch 20/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1455 - accuracy: 0.9489\n",
      "10/10 - 0s - loss: 1.0626 - accuracy: 0.5667\n",
      "test_loss :1.0625591278076172 \n",
      "test_accuracy: 0.5666666626930237\n"
     ]
    }
   ],
   "source": [
    "# 드롭 1번, batch_norm\n",
    "\n",
    "\n",
    "hp_1 = 64\n",
    "hp_2 = 32\n",
    "dense = 64\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(hp_1, (3,3), activation='relu', input_shape=(28,28,3))) # 컬러 이미지이므로 1 아니고 3\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(hp_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dropout(0.5)) # 드롭아웃 추가. 비율은 50%\n",
    "model.add(keras.layers.Dense(dense, activation='relu'))\n",
    "#model.add(keras.layers.Dropout(0.5)) # 드롭아웃 추가. 비율은 50%\n",
    "#model.add(keras.layers.Dense(32, kernel_regularizer='l1'))  # L1 정규화 적용\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(3, activation='softmax')) # 가위, 바위, 보 -> 3개 클래스로 분류\n",
    "\n",
    "#model.summary()\n",
    "epoch = 20\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs= epoch)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose= 2)\n",
    "print(\"test_loss :{} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 3.2940 - accuracy: 0.3800\n",
      "Epoch 2/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 2.2559 - accuracy: 0.4947\n",
      "Epoch 3/20\n",
      "113/113 [==============================] - 0s 3ms/step - loss: 1.5566 - accuracy: 0.6206\n",
      "Epoch 4/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.1649 - accuracy: 0.6878\n",
      "Epoch 5/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.8915 - accuracy: 0.7444\n",
      "Epoch 6/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.7371 - accuracy: 0.7786\n",
      "Epoch 7/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.6284 - accuracy: 0.8031\n",
      "Epoch 8/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.5517 - accuracy: 0.8203\n",
      "Epoch 9/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.8506\n",
      "Epoch 10/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.8586\n",
      "Epoch 11/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.8747\n",
      "Epoch 12/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8850\n",
      "Epoch 13/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8858\n",
      "Epoch 14/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3359 - accuracy: 0.9017\n",
      "Epoch 15/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3223 - accuracy: 0.8964\n",
      "Epoch 16/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2752 - accuracy: 0.9175\n",
      "Epoch 17/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2913 - accuracy: 0.9144\n",
      "Epoch 18/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2746 - accuracy: 0.9183\n",
      "Epoch 19/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.9228\n",
      "Epoch 20/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2781 - accuracy: 0.9183\n",
      "10/10 - 0s - loss: 0.9735 - accuracy: 0.5967\n",
      "test_loss :0.9735140800476074 \n",
      "test_accuracy: 0.596666693687439\n"
     ]
    }
   ],
   "source": [
    "# 드롭 1번, l1 정규화, batch_norm\n",
    "\n",
    "\n",
    "hp_1 = 64\n",
    "hp_2 = 32\n",
    "dense = 64\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(hp_1, (3,3), activation='relu', input_shape=(28,28,3))) # 컬러 이미지이므로 1 아니고 3\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(hp_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dropout(0.5)) # 드롭아웃 추가. 비율은 50%\n",
    "model.add(keras.layers.Dense(dense, activation='relu'))\n",
    "#model.add(keras.layers.Dropout(0.5)) # 드롭아웃 추가. 비율은 50%\n",
    "model.add(keras.layers.Dense(32, kernel_regularizer='l1'))  # L1 정규화 적용\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(3, activation='softmax')) # 가위, 바위, 보 -> 3개 클래스로 분류\n",
    "\n",
    "#model.summary()\n",
    "epoch = 20\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs= epoch)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose= 2)\n",
    "print(\"test_loss :{} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.1024 - accuracy: 0.3514\n",
      "Epoch 2/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.0899 - accuracy: 0.3719\n",
      "Epoch 3/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.0037 - accuracy: 0.4850\n",
      "Epoch 4/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.8699 - accuracy: 0.5964\n",
      "Epoch 5/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.7586 - accuracy: 0.6633\n",
      "Epoch 6/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.6663 - accuracy: 0.7175\n",
      "Epoch 7/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.6069 - accuracy: 0.7472\n",
      "Epoch 8/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.7728\n",
      "Epoch 9/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7897\n",
      "Epoch 10/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.8133\n",
      "Epoch 11/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8400\n",
      "Epoch 12/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8356\n",
      "Epoch 13/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3802 - accuracy: 0.8564\n",
      "Epoch 14/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8661\n",
      "Epoch 15/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8711\n",
      "Epoch 16/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2978 - accuracy: 0.8961\n",
      "Epoch 17/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3031 - accuracy: 0.8839\n",
      "Epoch 18/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2665 - accuracy: 0.9019\n",
      "Epoch 19/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2585 - accuracy: 0.9022\n",
      "Epoch 20/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.2807 - accuracy: 0.8964\n",
      "10/10 - 0s - loss: 1.3503 - accuracy: 0.5133\n",
      "test_loss :1.350256323814392 \n",
      "test_accuracy: 0.5133333206176758\n"
     ]
    }
   ],
   "source": [
    "# 드롭 2번\n",
    "\n",
    "hp_1 = 64\n",
    "hp_2 = 32\n",
    "dense = 64\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(hp_1, (3,3), activation='relu', input_shape=(28,28,3))) # 컬러 이미지이므로 1 아니고 3\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(hp_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dropout(0.5)) # 드롭아웃 추가. 비율은 50%\n",
    "model.add(keras.layers.Dense(dense, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5)) # 드롭아웃 추가. 비율은 50%\n",
    "#model.add(keras.layers.Dense(32, kernel_regularizer='l1'))  # L1 정규화 적용\n",
    "#model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(3, activation='softmax')) # 가위, 바위, 보 -> 3개 클래스로 분류\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "epoch = 20\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs= epoch)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose= 2)\n",
    "print(\"test_loss :{} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 2.7294 - accuracy: 0.3647\n",
      "Epoch 2/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.4715 - accuracy: 0.4583\n",
      "Epoch 3/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.0610 - accuracy: 0.5364\n",
      "Epoch 4/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.9735 - accuracy: 0.5864\n",
      "Epoch 5/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.9173 - accuracy: 0.6228\n",
      "Epoch 6/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.8656 - accuracy: 0.6508\n",
      "Epoch 7/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.8464 - accuracy: 0.6625\n",
      "Epoch 8/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.7779 - accuracy: 0.6958\n",
      "Epoch 9/20\n",
      "113/113 [==============================] - 0s 3ms/step - loss: 0.7407 - accuracy: 0.7203\n",
      "Epoch 10/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.7094 - accuracy: 0.7406\n",
      "Epoch 11/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.6610 - accuracy: 0.7606\n",
      "Epoch 12/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.6380 - accuracy: 0.7744\n",
      "Epoch 13/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.6031 - accuracy: 0.7847\n",
      "Epoch 14/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.5917 - accuracy: 0.7903\n",
      "Epoch 15/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.5610 - accuracy: 0.8036\n",
      "Epoch 16/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.5357 - accuracy: 0.8275\n",
      "Epoch 17/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.8292\n",
      "Epoch 18/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.8425\n",
      "Epoch 19/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.8433\n",
      "Epoch 20/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.8533\n",
      "10/10 - 0s - loss: 1.6518 - accuracy: 0.4933\n",
      "test_loss :1.6518073081970215 \n",
      "test_accuracy: 0.4933333396911621\n"
     ]
    }
   ],
   "source": [
    "# 드롭 2, l1 정규화\n",
    "hp_1 = 64\n",
    "hp_2 = 32\n",
    "dense = 64\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(hp_1, (3,3), activation='relu', input_shape=(28,28,3))) # 컬러 이미지이므로 1 아니고 3\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(hp_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dropout(0.5)) # 드롭아웃 추가. 비율은 50%\n",
    "model.add(keras.layers.Dense(dense, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5)) # 드롭아웃 추가. 비율은 50%\n",
    "model.add(keras.layers.Dense(32, kernel_regularizer='l1'))  # L1 정규화 적용\n",
    "#model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(3, activation='softmax')) # 가위, 바위, 보 -> 3개 클래스로 분류\n",
    "\n",
    "#model.summary()\n",
    "epoch = 20\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs= epoch)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose= 2)\n",
    "print(\"test_loss :{} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.3936 - accuracy: 0.3486\n",
      "Epoch 2/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.1990 - accuracy: 0.3719\n",
      "Epoch 3/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.0377 - accuracy: 0.4672\n",
      "Epoch 4/20\n",
      "113/113 [==============================] - 0s 3ms/step - loss: 0.9449 - accuracy: 0.5489\n",
      "Epoch 5/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.8475 - accuracy: 0.6228\n",
      "Epoch 6/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.7633 - accuracy: 0.6692\n",
      "Epoch 7/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.7103\n",
      "Epoch 8/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.6359 - accuracy: 0.7297\n",
      "Epoch 9/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.6069 - accuracy: 0.7458\n",
      "Epoch 10/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.5573 - accuracy: 0.7692\n",
      "Epoch 11/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7917\n",
      "Epoch 12/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.8061\n",
      "Epoch 13/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.8253\n",
      "Epoch 14/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.8306\n",
      "Epoch 15/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8306\n",
      "Epoch 16/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3913 - accuracy: 0.8469\n",
      "Epoch 17/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8564\n",
      "Epoch 18/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8575\n",
      "Epoch 19/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3571 - accuracy: 0.8653\n",
      "Epoch 20/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3501 - accuracy: 0.8681\n",
      "10/10 - 0s - loss: 1.5884 - accuracy: 0.5467\n",
      "test_loss :1.5884288549423218 \n",
      "test_accuracy: 0.54666668176651\n"
     ]
    }
   ],
   "source": [
    "# 드롭 2, batch_norm\n",
    "hp_1 = 64\n",
    "hp_2 = 32\n",
    "dense = 64\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(hp_1, (3,3), activation='relu', input_shape=(28,28,3))) # 컬러 이미지이므로 1 아니고 3\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(hp_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dropout(0.5)) # 드롭아웃 추가. 비율은 50%\n",
    "model.add(keras.layers.Dense(dense, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5)) # 드롭아웃 추가. 비율은 50%\n",
    "#model.add(keras.layers.Dense(32, kernel_regularizer='l1'))  # L1 정규화 적용\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(3, activation='softmax')) # 가위, 바위, 보 -> 3개 클래스로 분류\n",
    "\n",
    "#model.summary()\n",
    "epoch = 20\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs= epoch)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose= 2)\n",
    "print(\"test_loss :{} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 3.2078 - accuracy: 0.3378\n",
      "Epoch 2/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 2.1837 - accuracy: 0.3858\n",
      "Epoch 3/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.5728 - accuracy: 0.4747\n",
      "Epoch 4/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.2927 - accuracy: 0.5189\n",
      "Epoch 5/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.0927 - accuracy: 0.5997\n",
      "Epoch 6/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.9593 - accuracy: 0.6594\n",
      "Epoch 7/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.8394 - accuracy: 0.7019\n",
      "Epoch 8/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.7365 - accuracy: 0.7522\n",
      "Epoch 9/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.7041 - accuracy: 0.7458\n",
      "Epoch 10/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.6261 - accuracy: 0.7897\n",
      "Epoch 11/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.5989 - accuracy: 0.7958\n",
      "Epoch 12/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.5645 - accuracy: 0.8133\n",
      "Epoch 13/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.8222\n",
      "Epoch 14/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.8344\n",
      "Epoch 15/20\n",
      "113/113 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.8478\n",
      "Epoch 16/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.8567\n",
      "Epoch 17/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8686\n",
      "Epoch 18/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4060 - accuracy: 0.8722\n",
      "Epoch 19/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.4050 - accuracy: 0.8686\n",
      "Epoch 20/20\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.3975 - accuracy: 0.8775\n",
      "10/10 - 0s - loss: 1.3800 - accuracy: 0.4800\n",
      "test_loss :1.3799957036972046 \n",
      "test_accuracy: 0.47999998927116394\n"
     ]
    }
   ],
   "source": [
    "# 드롭2, l1 정규화, batch_norm\n",
    "hp_1 = 64\n",
    "hp_2 = 32\n",
    "dense = 64\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(hp_1, (3,3), activation='relu', input_shape=(28,28,3))) # 컬러 이미지이므로 1 아니고 3\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(hp_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dropout(0.5)) # 드롭아웃 추가. 비율은 50%\n",
    "model.add(keras.layers.Dense(dense, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5)) # 드롭아웃 추가. 비율은 50%\n",
    "model.add(keras.layers.Dense(32, kernel_regularizer='l1'))  # L1 정규화 적용\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(3, activation='softmax')) # 가위, 바위, 보 -> 3개 클래스로 분류\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "epoch = 20\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs= epoch)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose= 2)\n",
    "print(\"test_loss :{} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 결론\n",
    "#### 드롭아웃 1번, L1 Regularization 1번 설정해준 모델이 가장 높은 정확도를 내는 모델입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 1/20  \n",
    "113/113 [==============================] - 0s 2ms/step - loss: 2.7771 - accuracy: 0.3875  \n",
    "Epoch 2/20  \n",
    "113/113 [==============================] - 0s 2ms/step - loss: 1.4480 - accuracy: 0.4917  \n",
    "Epoch 3/20  \n",
    "113/113 [==============================] - 0s 2ms/step - loss: 0.9801 - accuracy: 0.6097  \n",
    "Epoch 4/20  \n",
    "113/113 [==============================] - 0s 2ms/step - loss: 0.8626 - accuracy: 0.6636  \n",
    "Epoch 5/20  \n",
    "113/113 [==============================] - 0s 2ms/step - loss: 0.7794 - accuracy: 0.7050  \n",
    "Epoch 6/20  \n",
    "113/113 [==============================] - 0s 2ms/step - loss: 0.7023 - accuracy: 0.7408  \n",
    "Epoch 7/20  \n",
    "113/113 [==============================] - 0s 2ms/step - loss: 0.6702 - accuracy: 0.7469  \n",
    "Epoch 8/20  \n",
    "113/113 [==============================] - 0s 2ms/step - loss: 0.6048 - accuracy: 0.7783  \n",
    "Epoch 9/20  \n",
    "113/113 [==============================] - 0s 2ms/step - loss: 0.5735 - accuracy: 0.7969  \n",
    "Epoch 10/20  \n",
    "113/113 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.8203  \n",
    "Epoch 11/20  \n",
    "113/113 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.8286  \n",
    "Epoch 12/20  \n",
    "113/113 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.8400  \n",
    "Epoch 13/20  \n",
    "113/113 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.8533  \n",
    "Epoch 14/20  \n",
    "113/113 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.8628  \n",
    "Epoch 15/20  \n",
    "113/113 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.8644  \n",
    "Epoch 16/20  \n",
    "113/113 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.8736  \n",
    "Epoch 17/20  \n",
    "113/113 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8869  \n",
    "Epoch 18/20  \n",
    "113/113 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8936  \n",
    "Epoch 19/20  \n",
    "113/113 [==============================] - 0s 2ms/step - loss: 0.3364 - accuracy: 0.8969  \n",
    "Epoch 20/20  \n",
    "113/113 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.9036  \n",
    "10/10 - 0s - loss: 1.2475 - accuracy: 0.6100  \n",
    "test_loss :1.2475314140319824    \n",
    "test_accuracy: 0.6100000143051147  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결론 및 회고\n",
    "\n",
    "모델의 성능을 좌우하는 하이퍼파라미터 값을 조절하면서 최적의 모델을 찾을 수 있었습니다.   \n",
    "\n",
    "학습 결과,  \n",
    "하이퍼파라미터 값이 __hp_1 = 64, hp_2 = 32, dense = 64, epoch = 20__ 이고   \n",
    "__드롭아웃 레이어 1번, l1 정규화__ 의 정규화 함수를 추가해준 모델이 가장 좋은 성능의 모델이었습니다.  \n",
    "최종적으로 __test_loss :1.2475314140319824,   test_accuracy: 0.6100000143051147의 결과__를 얻었습니다.   \n",
    "\n",
    "프로젝트를 수행하면서 전반적인 학습과정에 익숙해지고 과대적합이 일어났을 시 진행하는 정규화라는 개념에 대해 이해할 수 있었습니다.   \n",
    "결과적으로는 루브릭 평가 기준을 맞춘 모델을 만들 수 있었지만, 학습하다보면 계속 그 결과가 바뀌기 때문에 사실 이 결과가 가장 최고 성능의 모델이라는 확신을 하기 어렵습니다. 아마 다시 코드를 돌린다면 또 다른 결과가 나올지도 모릅니다.   \n",
    "저의 프로젝트의 특이점이 있다면 학습 과정에서 모든 하이퍼파라미터 경우의 수를 고려해서 전부 학습 시켰다는 점입니다. 이는 가장 직관적이고 확실한 방법이지만 시간적인 측면에서 효율적이지는 않다고 생각합니다. 이 방법말고 또 다른 방법이 있는지에 대해 계속 고민하였지만 결국 이렇다 할 방법을 찾아내지 못했습니다.   \n",
    "프로젝트를 하면서 이상했던 점은 300개의 train set으로 학습시킨 모델과 3600개의 train set으로 학습시킨 모델이 큰 차이가 없었다는 점입니다. 데이터가 많으면 많을 수록 정확도가 올라가기 때문에 10배 가까이 늘어난 데이터셋에 비례하게 증가할 accuracy 값을 기대했으나 별 차이가 없었습니다. 데이터 자체의 문제가 있었던 것인지, 비교도 안되게 더 큰 데이터 셋이 필요했던 것인지, 아니면 모델이 적합하지 않았던 것인지 아직 모호합니다.  \n",
    "앞으로 프로젝트를 계속 수행하면서 모델을 더 잘 이해할 수 있고 효과적인 학습 방법을 찾기 위해 더 많이 공부할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
