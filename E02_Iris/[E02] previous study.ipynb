{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-3. Iris의 세 가지 품종, 분류해 볼까요? (2) 데이터 준비, 그리고 자세히 살펴보기는 기본!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그럼 이제 정말 데이터셋을 가져와 보도록 하겠습니다!\n",
    "소개해드린 scikit-learn의 예제 데이터셋은 다음과 같이 sklearn 라이브러리의 datasets 패키지 안에 있습니다.\n",
    "load_iris를 import 해와서 iris 데이터를 로딩해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DESCR', 'data', 'feature_names', 'filename', 'frame', 'target', 'target_names']\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "print(dir(iris))\n",
    "print(type(dir(iris)))\n",
    "\n",
    "# dir() 는 객체가 어떤 변수와 메서드를 가지고 있는지 나열"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "잘 로딩이 되셨나요?\n",
    "iris에는 어떤 정보들이 담겼을지, keys() 라는 메서드로 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "네, iris에는 data, target, frame, target_names, DESCR, feature_names, filename 까지 총 6개의 정보가 담겨있군요.\n",
    "\n",
    "차근차근 하나씩 확인해 보겠습니다.\n",
    "가장 중요한 데이터는 다음과 같이 iris_data 변수에 저장한 후, 데이터의 크기를 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "iris_data = iris.data\n",
    "\n",
    "print(iris_data.shape)\n",
    "\n",
    "# shape는 배열의 형상 정보를 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "네, 위에서 확인했듯 총 150개의 데이터가 각각 4개의 정보를 담고 있는 것으로 보이는군요.\n",
    "샘플로 하나의 데이터만 확인해 볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.1, 3.5, 1.4, 0.2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0번 index로 접근해서 확인해 보니, 총 네 개의 숫자가 나옵니다.\n",
    "이는 위에서 확인했던대로, 순서대로 sepal length, sepal width, petal length, petal width 를 나타냅니다.\n",
    "\n",
    "이쯤에서 우리가 풀려고 했던 문제를 다시 떠올려봅시다. 우리는 어떤 문제를 풀려고 했었죠?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "네, 우리는 꽃잎과 꽃받침의 길이가 주어지는 경우 그 꽃은 세 가지의 붓꽃 품종 중 어떤 것인지를 맞추어 보고 싶었습니다.\n",
    "따라서 우리는 머신러닝 모델에게 꽃잎, 꽃받침의 길이와 폭 정보를 입력했을 때 붓꽃의 품종을 출력하도록 학습을 시켜야 하죠.\n",
    "\n",
    "여기서 이렇게 머신러닝 모델이 출력해야 하는 정답을 라벨(label), 또는 타겟(target) 이라고 합니다.\n",
    "우리의 붓꽃 데이터에서 타겟 정보는 다음과 같이 target으로 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_label = iris.target\n",
    "print(iris_label.shape)\n",
    "iris_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "네, iris 데이터의 target을 iris_label이라는 변수에 저장해 보았는데요.\n",
    "\n",
    "길이와 형태를 확인하니 총 150개의 데이터가 들어있고, 각 값은 0, 1, 또는 2로 나타나는 것을 확인할 수 있습니다. 이 숫자들은 무엇을 나타내는 걸까요?\n",
    "라벨의 이름은 다음과 같이 target_names에서 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리가 알고 있던대로 setosa, versicolor, virginica 순서대로 담겨있군요.\n",
    "이 순서 그대로 0이라면 setosa, 1이라면 versicolor, 2라면 virginica를 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(iris.DESCR) # 데이터 셋의 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.feature_names   #4r개의 각 feature에 대한 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ssac18/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/datasets/data/iris.csv'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.filename  # 데이터 셋 파일이 저장된 경로"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-4. 첫 번째 머신러닝 실습, 간단하고도 빠르게! (1) 머신러닝 모델을 학습시키기 위한 문제지와 정답지 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터가 준비되었으니 이제 바로 분류하는 머신러닝 모델을 학습시키는 실습을 진행해 보죠.\n",
    "\n",
    "처음이라면 복잡하게 느껴질 수도 있지만, 하나씩 따라오시다보면 사실 간단한 과정이라는 것을 느낄 수 있을 겁니다.\n",
    "단계별로, 시작해 보겠습니다!\n",
    "\n",
    "pandas를 들어보셨나요?\n",
    "판다스라고 불리는 이 라이브러리는 파이썬에서 표 형태로 이루어진 2차원 배열 데이터를 다루는 데에 가장 많이 쓰이는 도구입니다. 표 데이터를 활용해서 데이터 분석을 하기도 하고, 또는 대형 데이터의 여러 통계량을 다루기에도 최적화가 되어있죠.\n",
    "\n",
    "iris 데이터 또한 행과 열이 있는 2차원 데이터이므로 우리도 pandas를 활용해서 다뤄볼 것입니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas는 코드에서 굉장히 많이 쓰이기 때문에 pd라는 약어로 많이 사용합니다.\n",
    "\n",
    "붓꽃 데이터셋을 pandas가 제공하는 DataFrame 이라는 자료형으로 변환해 보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.1               3.5                1.4               0.2\n",
       "1                  4.9               3.0                1.4               0.2\n",
       "2                  4.7               3.2                1.3               0.2\n",
       "3                  4.6               3.1                1.5               0.2\n",
       "4                  5.0               3.6                1.4               0.2\n",
       "..                 ...               ...                ...               ...\n",
       "145                6.7               3.0                5.2               2.3\n",
       "146                6.3               2.5                5.0               1.9\n",
       "147                6.5               3.0                5.2               2.0\n",
       "148                6.2               3.4                5.4               2.3\n",
       "149                5.9               3.0                5.1               1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame 을 만들면서 data에는 iris_data를 넣어주고, 각 컬럼에는 feature_names로 이름을 붙여주었습니다.\n",
    "한 가지 더, 정답 데이터도 함께 있다면 데이터를 다루기 더 편리하겠죠. label이라는 컬럼을 추가해주겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     label  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "..     ...  \n",
       "145      2  \n",
       "146      2  \n",
       "147      2  \n",
       "148      2  \n",
       "149      2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df[\"label\"] = iris.target #target(정답)을 라벨이라는 컬럼으로 지정하고 추가\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "네, [\"label\"] 이라는 코드로 라벨 컬럼을 추가해주었습니다. 아까 확인했던대로 0~2 사이의 값들이 잘 들어간 것으로 보이네요.\n",
    "\n",
    "여기서 4가지의 feature 데이터들은 바로 머신러닝 모델이 풀어야 하는 문제지와 같습니다.\n",
    "예를 들어, [5.1, 3.5, 1.4, 0.2]라는 문제가 주어진다면 모델은 0, 즉 setosa라는 답을 맞추어야 하는 것이죠.\n",
    "따라서 0, 1, 2와 같이 표현된 label 데이터는 머신러닝 모델에게 정답지라고 할 수 있습니다.\n",
    "\n",
    "정리하자면 다음과 같습니다.\n",
    "\n",
    "* 문제지 : 머신러닝 모델에게 입력되는 데이터. __feature__라고 부르기도 한다. 변수 이름으로는 X를 많이 사용한다.\n",
    "* 정답지 : 머신러닝 모델이 맞추어야 하는 데이터. __label__, 또는 __target__이라고 부르기도 한다. 변수 이름으로는 y를 많이 사용한다.\n",
    "\n",
    "여기서 feature, label, target 과 같은 용어들을 잘 기억해두길 바랍니다! 머신러닝에서는 아주 많이 쓰이는 기본 용어이니까요 :)\n",
    "\n",
    "그럼 이제 pandas를 활용한 데이터 확인까지 했으니 바로 모델을 학습시켜보겠습니다.\n",
    "\n",
    "머신러닝 모델을 학습시키려면 한 가지 장치가 필요합니다.\n",
    "바로 학습에 사용하는 training dataset과 모델의 성능을 평가하는 데 사용하는 test dataset으로 데이터셋을 나누는 작업이 필요하죠.\n",
    "\n",
    "우리에게는 150개의 데이터가 있지만, 이 150개를 모두 학습시키는 데에 사용해버리면 학습이 완료된 모델의 성능을 공정하게 평가할 수 없기 때문입니다.\n",
    "데이터셋을 분리하는 것은 scikit-learn이 제공하는 train_test_split 이라는 함수로 간단하게 할 수 있습니다.\n",
    "\n",
    "sklearn.model_selection 패키지의 train_test_split을 활용하여, 다음과 같이 trainig dataset과 test dataset을 간단히 분리해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 개수: 120 X_test 개수: 30\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data,\n",
    "                                                   iris_label,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=7)\n",
    "\n",
    "print('X_train 개수:', len(X_train), 'X_test 개수:', len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 번째 파라미터인 iris_data는 문제지, 즉 feature 입니다. 모델이 품종을 맞추기 위해 입력받는 특징 데이터이죠. iris 데이터셋에서는 4가지의 특징 정보가 있었습니다.\n",
    "두 번째 파라미터인 iris_label은 모델이 맞추어야 하는 정답값, 즉 label입니다. 총 세 가지 품종이 있었죠.\n",
    "\n",
    "이렇게 넣어줌으로써 우리는 학습용 데이터와 테스트용 데이터를 생성하며 각 데이터에서 4개의 feature 데이터만 있는 X, 그리고 정답 label 데이터만 있는 y를 얻을 수 있습니다.\n",
    "\n",
    "X 데이터셋을 머신러닝 모델에 입력하고, 그에 따라 모델이 내뱉는 품종 예측 결과를 정답인 y와 비교하며 점차 정답을 맞추어나가도록 학습을 시킬 것입니다.\n",
    "X와 y 뒤에 붙은 train과 test는 당연히 위에서 말했던 학습용 데이터와 테스트용 데이터를 뜻합니다.\n",
    "\n",
    "또한 세 번째 인자인 test_size로는 test dataset의 크기를 조절할 수 있습니다. 0.2는 전체의 20%를 테스트 데이터로 사용하겠다는 것을 나타냅니다.\n",
    "\n",
    "마지막으로 쓰인 random_state는 train데이터와 test데이터를 분리(split)하는데 적용되는 랜덤성을 결정합니다. 위에서 데이터를 출력했을때 라벨이 0부터 순서대로 정렬된 것을 보셨을 겁니다.\n",
    "\n",
    "만약 이 데이터 그대로 학습용 데이터와 테스트용 데이터를 나눈다면 뒤쪽의 20%가 테스트용 데이터셋으로 만들어지기 때문에 테스트용 데이터셋은 라벨이 2인 데이터로만 구성됩니다.\n",
    "\n",
    "이런 데이터셋을 테스트용으로 사용한다면 학습이 제대로 되었는지 확인할수가 없겠죠? 그래서 데이터를 분리할 때 랜덤으로 섞는 과정이 필요하고 random_state가 이 역할을 하게되는 것이죠.\n",
    "\n",
    "컴퓨터에서의 랜덤은 아무리 랜덤이라고 해도 특정 로직에 따라 결정되는 랜덤이기 때문에 완벽한 랜덤이라고 할 수 없습니다.\n",
    "그러한 랜덤을 조절할 수 있는 값이 바로 random_state, 또는 random_seed입니다. 이 값이 같다면 코드는 항상 같은 랜덤 결과를 나타냅니다.\n",
    "랜덤인데 왜 같은 결과를 원하냐구요? 내가 실험한 결과를 다른 사람의 컴퓨터에서도 재현가능(reproducible) 하게 하려면 같은 랜덤시드가 필요할 때가 있답니다.\n",
    "랜덤성을 조절하고 싶지 않다면, 해당 인자는 없어도 코드상의 문제는 없습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 4), (120,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30, 4), (30,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 1, 0, 2, 1, 0, 0, 0, 0, 2, 2, 1, 2, 2, 1, 0, 1, 1, 2, 0, 0, 0,\n",
       "        2, 0, 2, 1, 1, 1, 0, 0, 0, 1, 2, 1, 1, 0, 2, 0, 0, 2, 2, 0, 2, 0,\n",
       "        1, 2, 1, 0, 1, 0, 2, 2, 1, 0, 0, 1, 2, 0, 2, 2, 1, 0, 1, 0, 2, 2,\n",
       "        0, 0, 2, 1, 2, 2, 1, 0, 0, 2, 0, 0, 1, 2, 2, 1, 1, 0, 2, 0, 0, 1,\n",
       "        1, 2, 0, 1, 1, 2, 2, 1, 2, 0, 1, 1, 0, 0, 0, 1, 1, 0, 2, 2, 1, 2,\n",
       "        0, 2, 1, 1, 0, 2, 1, 2, 1, 0]),\n",
       " array([2, 1, 0, 1, 2, 0, 1, 1, 0, 1, 1, 1, 0, 2, 0, 1, 2, 2, 0, 0, 1, 2,\n",
       "        1, 2, 2, 2, 1, 1, 2, 2]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 확인했던 label과는 다르게 0, 1, 2가 무작위로 섞여 있는 것을 확인할 수 있습니다.\n",
    "train 데이터와 test 데이터에 각 품종 카테고리가 균일하게 잘 섞일 수 있도록 train_test_split 함수가 데이터셋을 만들어냈다는 뜻이기도 하죠.\n",
    "\n",
    "이제 정말 머신러닝 모델을 학습시키기 위한 모든 준비가 끝났습니다. 바로 모델 학습 단계로 넘어가보겠습니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-5. 첫 번째 머신러닝 실습, 간단하고도 빠르게! (2) 첫 번째 머신러닝 모델 학습시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝은 크게 지도학습 (Supervised Learning), 비지도 학습 (Unsupervised Learning)이라는 두 가지로 구분됩니다.\n",
    "간단히 말해서 지도학습은 지도받을 수 있는, 즉 정답이 있는 문제에 대해 학습하는 것을 말하고, 반대로 비지도학습은 정답이 없는 문제를 학습하는 것을 말합니다.\n",
    "\n",
    "저희가 지금 해결하고자 하는 붓꽃 품종 문제는 어디에 해당할까요? 데이터에는 정답이 있었나요, 없었나요?\n",
    "\n",
    "네, 저희에게는 label이라는 정답지가 있었죠. 모델이 지도받을 수 있다는 이야기입니다. 즉, 붓꽃 품종 문제는 지도학습에 해당합니다.\n",
    "\n",
    "지도학습은 다시 두 가지로 나눌 수 있는데, 바로 분류(Classification)와 회귀(Regression)입니다.\n",
    "분류는 입력받은 데이터를 특정 카테고리 중 하나로 분류해내는 문제를, 회귀는 입력받은 데이터에 따라 특정 필드의 수치를 맞추는 문제를 말합니다.\n",
    "\n",
    "다시 한 번 또 고민해 보죠. 붓꽃 품종 문제는 분류 문제인가요, 회귀 문제인가요?\n",
    "\n",
    "네, 붓꽃 품종 문제는 feature 데이터를 입력받으면 setosa, versicolor, virginica 세 가지 품종 중 하나로 분류해내는, 분류 문제였습니다.\n",
    "\n",
    "그렇다면 회귀 문제는 어떤 것이 있을까요?\n",
    "예를 들어, 집에 대한 정보(평수, 위치, 층수 등)를 입력받아 그 집의 가격을 맞추는 문제는 회귀 문제에 해당합니다.\n",
    "카테고리를 분류하는 것이 아니라, 실제 값의 수치를 어림해서 맞추는 거죠."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자, 그러면 정리해봅시다.\n",
    "\n",
    "우리가 해결하고자 하는 붓꽃 문제는\n",
    "\n",
    "* 첫 번째, 머신러닝 중 정답이 있고 그 정답을 맞추기 위해 학습하는 지도 학습(Supervised Learning)이며,\n",
    "* 지도학습 중에서는 특정 카테고리 중 주어진 데이터가 어떤 카테고리에 해당하는지를 맞추는 분류(Classification) 문제\n",
    "라고 할 수 있겠습니다.\n",
    "\n",
    "그러면 여기까지 정리가 되었으니 우리는 무슨 머신러닝 모델을 써야할지 명확해집니다. 지도학습 중에서도 분류를 할 수 있는 모델을 사용하면 되죠.\n",
    "\n",
    "분류 모델은 아주 다양하지만, 그 중 저희는 첫 번째로 Decision Tree 모델을 사용해 보도록 하겠습니다.\n",
    "Decision Tree 는 직관적이면서도 간단하게 사용할 수 있어 분류 문제를 풀 때 가장 기본적으로 쓰이는 모델 중 하나입니다.\n",
    "\n",
    "Decision Tree의 알고리즘을 설명하는 다음 글을 한 번 읽어보죠. 비교적 수학적인 내용이 많아서 쉽지 않을 수 있지만, 이해가 잘 안가더라도 편하게 읽어보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "의사결정나무는 구분 뒤 각 영역의 순도(homogeneity)가 증가/불확실성(엔트로피)가 최대한 감소하도록 하는 방향으로 학습을 진행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "네, 간단히 말해 Decision Tree는 의사 결정을 할, 즉 데이터를 분리할 어떤 경계를 찾아내어 데이터를 체에 거르듯 한 단계씩 분류해나가는 모델입니다.\n",
    "이 과정에서 엔트로피, 정보량, 지니불순도 등의 정보이론 개념이 포함됩니다. 이러한 내용은 오늘 실습에서 모두 자세히 다루지는 않을 것이지만, 머신러닝 모델의 알고리즘을 이해하기 위해서는 이러한 배경에 대한 공부가 필수적입니다. 다행히 기본 개념에 대한 좋은 설명자료들이 구글에 넘치도록 많으니, 꼭 한 번 보다 깊은 내용에 대해 학습하는 것을 추천합니다!\n",
    "\n",
    "Decision Tree는 sklearn.tree 패키지 안에 DecisionTreeClassifier 라는 이름으로 내장되어 있습니다.\n",
    "모델을 import해서 가져오고, decision_tree 라는 변수에 모델을 저장해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "print(decision_tree._estimator_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자, 그러면 모델은 어떻게 학습시킬까요?\n",
    "\n",
    "놀라지 마세요. 지금까지 길게 거쳐온 과정이 무색하게, 모델 학습은 아주 간단하답니다.\n",
    "물론 이 간단함은 scikit-learn이 모델 학습을 편리하게 할 수 있도록 설계한 API 구조 덕이기도 합니다.\n",
    "\n",
    "모델 학습은 우리가 준비해 둔 X_train 와 y_train 데이터로, 다음 한 줄이면 완료됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 눈여겨 볼 점은 학습하는 메서드의 이름이 fit이라는 점입니다.\n",
    "training dataset 으로 모델을 학습시킨다는 것은, 달리 말하면 training dataset에 맞게 모델을 fitting, 즉 맞추는 것이라고 할 수 있습니다.\n",
    "training dataset에 있는 데이터들을 통해 어떠한 패턴을 파악하고, 그 패턴에 맞게 예측을 할 수 있도록 학습되기 때문입니다.\n",
    "\n",
    "즉, 다른 말로 하면 모델은 training dataset에 존재하지 않는 데이터에 대해서는 정확한 정답 카테고리가 무엇인지 알지 못합니다.\n",
    "다만 training dataset을 통해 학습한 패턴으로 새로운 데이터가 어떤 카테고리에 속할지 예측할 뿐이죠.\n",
    "\n",
    "그렇기 때문에 새로운 데이터에 대해서도 잘 맞출 수 있기 위해서는 training dataset이 어떻게 구성되어 있는지가 매우 중요합니다.\n",
    "더 다양한, 더 일반화 된 데이터로 학습이 될수록 새로운 데이터에 대해서도 잘 맞출 수 있는 것이죠."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-6. 첫 번째 머신러닝 실습, 간단하고도 빠르게! (3) 첫 번째 머신러닝 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 1, 2, 0, 1, 1, 0, 1, 2, 1, 0, 2, 0, 2, 2, 2, 0, 0, 1, 2,\n",
       "       1, 1, 2, 2, 1, 1, 2, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = decision_tree.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_test 데이터에는 정답인 label이 없고 feature 데이터만 존재했습니다.\n",
    "따라서 학습이 완료된 decision_tree 모델에 X_test 데이터로 predict를 실행하면 모델이 예측한 y_pred을 얻게 됩니다.\n",
    "\n",
    "모델은 총 30개의 데이터에 대해 [2, 1, ...] 라는 예측 결과를 내놓았군요.\n",
    "실제 정답인 y_test와 비교해서 얼마나 맞았는지 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 1, 2, 0, 1, 1, 0, 1, 1, 1, 0, 2, 0, 1, 2, 2, 0, 0, 1, 2,\n",
       "       1, 2, 2, 2, 1, 1, 2, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "눈으로 간단히 비교해 봤을 때는 어느정도 잘 맞은 것 같지 않나요?\n",
    "\n",
    "예측한 결과에 대한 수치를 조금 더 편리하게 확인할 수 있는 방법이 있습니다.\n",
    "scikit-learn에서 성능 평가에 대한 함수들이 모여있는 sklearn.metrics 패키지를 이용하면 되죠.\n",
    "\n",
    "성능을 평가하는 방법에도 다양한 척도가 있는데, 그 중 일단 정확도(Accuracy)를 간단히 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "약 0.9이라는 수치가 나왔군요. 이는 90% 정도의 정확도를 보인다는 뜻입니다.\n",
    "\n",
    "정확도는 전체 개수 중 맞은 것의 개수의 수치를 나타냅니다. 다음과 같은 식으로 나타낼 수 있죠.\n",
    "\n",
    "정확도 = 예측 결과가 정답인 데이터의 개수 / 예측한 전체 데이터의 개수\n",
    "\n",
    "따라서, 우리의 모델은 30개의 데이터에 대해 예측을 했으니 그 중 맞은 것은 30 * 0.9 = 27 개라는 것을 역추적해 볼 수 있습니다.\n",
    "즉, 30개 중 27개는 옳은 카테고리로, 3개는 틀린 카테고리로 분류를 했나봅니다.\n",
    "\n",
    "90%의 정확도로 붓꽃의 품종을 잘 판단한다니, 아주 빠르게 학습시켜본 것에 비하면 꽤나 좋은 결과인 것 같지 않은가요?!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-7. 첫 번째 머신러닝 실습, 간단하고도 빠르게! (4) 다른 모델도 해 보고 싶다면? 코드 한 줄만 바꾸면 돼!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 번째 모델을 학습도 시켜보고, 성능도 평가해봤으니 이제는 다른 모델들도 활용해 보겠습니다!\n",
    "\n",
    "다른 모델들을 사용하는 것 또한, 편리하게 설계된 scikit-learn 덕분에 아주 간단합니다.\n",
    "scikit-learn을 사용하는 것에 익숙해진다면 심지어 한 줄의 코드만 수정해도 된다구요!\n",
    "\n",
    "다른 모델들을 다루기 전에 위에서 사용했던 Decision Tree 모델을 학습시키고 예측하는 과정을 한 번에 담아보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.91      0.83      0.87        12\n",
      "           2       0.83      0.91      0.87        11\n",
      "\n",
      "    accuracy                           0.90        30\n",
      "   macro avg       0.91      0.91      0.91        30\n",
      "weighted avg       0.90      0.90      0.90        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (1) 필요한 모듈 import\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# (2) 데이터 준비\n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_label = iris.target\n",
    "\n",
    "# (3) train, test 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, \n",
    "                                                    iris_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=7)\n",
    "\n",
    "# (4) 모델 학습 및 예측\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어떤가요? 위에서 여러가지를 배우면서 진행해서 굉장히 길게 늘어졌던 과정이 사실은 이렇게나 짧고 간단합니다.\n",
    "\n",
    "여기서 모델을 바꿔보고 싶다면 (4) 모델 학습 및 예측 부분에서 모델만 바꿔주면 되죠.\n",
    "모델이 바뀐다고 해도 위와 같이 진행되는 큰 흐름은 변하지 않으니 이 흐름을 잘 기억해두도록 합시다!\n",
    "\n",
    "이 외에 간단히 활용해 볼 수 있는 모델들을 만나보겠습니다. 먼저, Decision Tree를 여러개 모아놓은 RandomForest입니다.\n",
    "위에서 RandomForest는 Decision Tree 모델을 여러개 합쳐놓음으로써 Decision Tree의 단점을 극복한 모델이라고 소개했죠.\n",
    "이러한 기법을 앙상블(Ensemble) 기법이라고 합니다. 단일 모델을 여러 개 사용하는 방법을 취함으로써 모델 한 개만 사용할 때의 단점을 집단지성으로 극복하는 개념이죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       0.92      0.92      0.92        13\n",
      "           2       0.88      0.88      0.88         8\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.93      0.93      0.93        30\n",
      "weighted avg       0.93      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, \n",
    "                                                    iris_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=25)\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다른 scikit-learn 내장 분류모델\n",
    "___\n",
    "이 외에 scikit-learn에 내장된 기본 분류 모델들을 몇 가지 더 사용해 보겠습니다.\n",
    "오늘은 각 모델에 대한 깊은 이론적인 내용보다는, 사용해 볼 수 있는 것에 초점을 맞추어 연습을 해 볼 것입니다.\n",
    "각 모델에 대한 내용들을 이해하기 위한 좋은 글들을 하나씩 첨부하니, 꼭 한 번씩 읽고 넘어가기를 권합니다.\n",
    "\n",
    "코드 사용은 아시다시피 어렵지 않습니다. 전체 틀은 모두 같으니, 직접 코드를 짜보세요!\n",
    "\n",
    "__Support Vector Machine (SVM)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       1.00      0.92      0.96        13\n",
      "           2       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.96      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "print(svm_model._estimator_type)\n",
    "\n",
    "# 코드를 입력하세요\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Stochastic Gradient Descent Classifier (SGDClassifier)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         9\n",
      "           1       0.54      1.00      0.70        13\n",
      "           2       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.63        30\n",
      "   macro avg       0.51      0.56      0.50        30\n",
      "weighted avg       0.53      0.63      0.54        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ssac18/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_model = SGDClassifier()\n",
    "\n",
    "print(sgd_model._estimator_type)\n",
    "\n",
    "# 코드를 입력하세요\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Logistic Regression__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       1.00      0.92      0.96        13\n",
      "           2       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.96      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ssac18/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "print(logistic_model._estimator_type)\n",
    "\n",
    "# 코드를 입력하세요\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-8. 내 모델은 얼마나 똑똑한가? 다양하게 평가해 보기 (1) 정확도에는 함정이 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞에서 머신러닝 모델을 빠르게 학습시켜보고, 그 결과도 간단히 확인해 보았습니다.\n",
    "\n",
    "하지만, 사실 머신러닝에서는 모델을 학습시키는 것뿐만 아니라 그 성능을 정확히 평가하고 개선하는 것이 매우 중요합니다.\n",
    "위에서 정확도라는 척도를 통해 모델의 성능을 확인했던 것, 기억하시나요?\n",
    "\n",
    "모델의 성능을 평가하는 데에는 정확도뿐만 아니라 다른 척도들이 존재합니다.\n",
    "이번 스텝에서는 다른 척도들을 배워보고, 그 척도들을 간단한 방법으로 확인도 해 보도록 하겠습니다.\n",
    "\n",
    "### 정확도에는 함정이 있다\n",
    "---\n",
    "위에서 우리는 정확도로 모델의 성능을 평가해 보았습니다. 하지만 정확도에는 치명적인 함정이 있죠.\n",
    "\n",
    "어떤 함정이 있는지, 손글씨 데이터인 MNIST 데이터셋으로 확인해 보겠습니다.\n",
    "우리가 붓꽃 데이터를 사용했을 때처럼, 손글씨 데이터도 아래와 같은 코드로 간단히 가져올 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "digits.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "digits 라는 변수에 손글씨 데이터를 저장했고, 그 안에는 iris 데이터와 똑같이 몇 가지의 정보들이 있군요.\n",
    "\n",
    "가장 중요한 data를 먼저 확인해 보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_data = digits.data\n",
    "digits_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예상대로 64개의 숫자로 이루어진 배열(array)이 출력되었습니다. 각 숫자는 어떤 의미를 가질까요?\n",
    "\n",
    "손글씨 데이터는 이미지 데이터입니다. 따라서 각 숫자는 픽셀값을 의미하죠. 길이 64의 숫자 배열은 사실 (8 x 8) 크기의 이미지를 일렬로 쭉 펴놓은 것입니다.\n",
    "이미지는 어떻게 생겼는지 한 번 확인해 보겠습니다. 이미지를 보기 위해서는 matplotlib이라는 라이브러리가 필요합니다.\n",
    "\n",
    "matplotlib.pyplot을 plt라는 이름으로 가져오고, 이미지를 현재 화면에 보여주기 위해 %matplotlib inline이라는 코드를 추가하겠습니다.\n",
    "\n",
    "이미지는 다음과 같이 간단히 확인할 수 있습니다. 다만, 일렬로 펴진 64개 데이터를 (8, 8)로 reshape해주는 것을 잊으면 안 됩니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAADyUlEQVR4nO3dUVFjaRRG0T9TYyAWggSwkkgACSABL5FAJBALSCAS7higeZo6vZte6zF5+KiEXbeKB85u27YF9Pzzu38A4GvihChxQpQ4IUqcEPXvd2/udrsf+afc4/E4uvf6+jq2dblcxrZeXl7Gtm6329jWtG3bdl+97skJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEqG/PMfxUk+cR1lrrcDiMbe33+7Gtz8/Psa3T6TS2tdZa5/N5dO8rnpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IypxjuL+/H9uaPI+w1lp3d3djWx8fH2Nbb29vY1uTvx9rOccAfEOcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiMrcStnv92Nb1+t1bGut2fslk6Y/x7+NJydEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROi/spzDJfLZWzrJ5v8zm6329hWhScnRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTojLnGCb/3f79/f3Y1rTJEwmTn+P5fB7bqvDkhChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQtRu27Zfv7nb/frN/9nhcJiaWu/v72Nba6319PQ0tnU8Hse2Jr+zh4eHsa1p27btvnrdkxOixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oSozK2USY+Pj6N7z8/PY1vX63Vs63Q6jW39ZG6lwB9GnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBD17TkG4Pfx5IQocUKUOCFKnBAlTogSJ0T9ByioUst9Wxj9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(digits.data[0].reshape(8, 8), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(digits.data[i].reshape(8, 8), cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "네, 해상도가 낮은 이미지이기 때문에 흐릿하지만, 마음의 눈으로 보면 0부터 9까지의 숫자를 볼 수 있습니다.\n",
    "\n",
    "그렇다면 target 데이터는 어떨까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_label = digits.target\n",
    "print(digits_label.shape)\n",
    "digits_label[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "총 1797개의 데이터가 있고, 0부터 9까지의 숫자로 나타나는군요.\n",
    "바로 각 이미지 데이터가 어떤 숫자를 나타내는지를 담고 있는 데이터입니다.\n",
    "\n",
    "그러면, 우리는 어떤 문제를 풀어야 할까요?\n",
    "붓꽃 문제와 같이, 각 이미지 데이터가 입력되었을 때 그 이미지가 숫자 몇을 나타내는 이미지인지를 맞추는 분류 모델을 학습시키면 됩니다.\n",
    "\n",
    "다만, 이번에는 정확도의 함정을 확인하기 위한 실험이었기 때문에 약간의 장치를 넣어볼 것입니다.\n",
    "\n",
    "바로, 숫자 10개를 모두 분류하는 것이 아니라, 해당 이미지 데이터가 3인지 아닌지를 맞추는 문제로 변형해서 풀어보는 것입니다.\n",
    "즉, 입력된 데이터가 3이라면 3을, 3이 아닌 다른 숫자라면 0을 출력하도록 하는 모델을 생각해 보겠습니다.\n",
    "\n",
    "그러려면, 우리는 target인 digits_label을 살짝 변형할 필요가 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_label = [3 if i == 3 else 0 for i in digits_label]\n",
    "new_label[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "네, 기존의 label인 digits_label에서 숫자가 3이라면 그대로 3을, 아니라면 0을 가지는 new_label을 만드는거죠.\n",
    "\n",
    "이제 이 문제를 풀기 위해 다시 Decision Tree를 학습시켜보겠습니다. 모델 학습은 아주 간단했던 것, 기억하시죠?\n",
    "직접 코드를 짜보세요!\n",
    "\n",
    "Q15. digits_data와 new_label로 Decision Tree 모델을 학습시키고, 정확도를 확인해 보세요. 아래 코드 셀에서 실행한 후, 정답을 확인하세요.\n",
    "\n",
    "(힌트! train_test_split으로 학습 데이터와 테스트 데이터를 만든 후, 모델을 fit 시키고, predict를 통해 예측 결과를 만든 후 accuracy_score를 이용해 정확도를 측정하는 순서로 진행)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.975"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 코드를 입력하세요\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits_data,\n",
    "                                                    new_label,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "93.9%라는 높은 성능이 나왔군요! 👏🏼👏🏼👏🏼..\n",
    "\n",
    "바로 이곳에 함정이 있습니다. 어떤 함정일까요? 우리가 풀려고 했던 문제를 생각해봅시다.\n",
    "우리는 총 10개의 숫자 중 3에만 집중을 해서, 3이라면 3으로, 3이 아니라면 0으로 맞추는 문제로 변형했었죠.\n",
    "그런 이유로, 정답 데이터인 label은 0이 굉장히 많고 3은 적은 불균형 데이터가 되었습니다.\n",
    "9개의 숫자들은 label이 모두 0이 되었고, 3만 3으로 남아있었으니 대략 90%의 label이 모두 0이라는 이야기가 되죠.\n",
    "\n",
    "이것은 무엇을 의미할까요? 잠시 생각해봅시다. 🤔\n",
    "\n",
    "\n",
    "네, 바로 모델이 전혀 학습하지 않고 정답을 모두 0으로만 선택해도 정확도가 90%가량이 나오게 된다는 것입니다.\n",
    "실제로 확인해 보죠.\n",
    "\n",
    "길이는 y_pred와 같으면서 0으로만 이루어진 리스트를 fake_pred 라는 변수로 저장해 보고, 이 리스트와 실제 정답인 y_test간의 정확도를 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9055555555555556"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_pred = [0] * len(y_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, fake_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어떤가요? 우리는 어떠한 모델을 사용하지 않고 답을 0으로만 찍었을 뿐인데, 정확도가 92.5%가 나옵니다.\n",
    "이러한 문제는 불균형한 데이터, unbalanced 데이터에서 많이 발생할 수 있습니다.\n",
    "\n",
    "즉, 정확도는 정답의 분포에 따라 모델의 성능을 잘 평가하지 못하는 척도가 될 수 있는 것이죠.\n",
    "\n",
    "그렇기 때문에 분류 문제에서는 정확도 외에 다양한 평가 척도를 사용합니다. 무엇이 있는지 알아보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
