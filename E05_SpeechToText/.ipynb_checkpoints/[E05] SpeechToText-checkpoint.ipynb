{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-7. 프로젝트: Spectrogram classification 모델 구현\n",
    "\n",
    "### [루브릭]\n",
    "\n",
    "평가문항\t상세기준\n",
    "   1. 음성데이터를 2차원 Spectrogram 으로 변환하여 데이터셋을 구성하였다.  \n",
    "        -스펙트로그램 시각화 및 train/test 데이터셋 구성이 정상진행되었다.\n",
    "    \n",
    "    \n",
    "   2. 1,2차원 데이터를 처리하는 음성인식 모델이 정상 작동한다.  \n",
    "        -스펙트로그램을 입력받은 모델이 학습과정에서 안정적으로 수렴하며, evaluation/test 단계를 무리없이 진행가능하다.\n",
    "    \n",
    "    \n",
    "   3. 테스트셋 수행결과 음성인식 모델의 Accuracy가 일정 수준에 도달하였다.  \n",
    "        -evaluation 결과 75% 이상의 정확도를 달성하는 모델이 하나 이상 존재한다.\n",
    "    \n",
    "    \n",
    "### [학습 과정]\n",
    "1. 데이터 처리와 분류\n",
    "2. 학습을 위한 하이퍼파라미터 설정\n",
    "3. 데이터셋 구성\n",
    "4. 2차원 Spectrogram 데이터를 처리하는 모델 구성\n",
    "5. 학습 후, 학습이 어떻게 진행됐는지 그래프로 출력\n",
    "6. Test dataset을 이용해서 모델의 성능을 평가\n",
    "\n",
    "### [결론 및 회고]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 데이터 처리와 분류\n",
    "* 라벨 데이터 처리하기\n",
    "* sklearn의 train_test_split함수를 이용하여 train, test 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "data_path = os.getenv(\"HOME\")+'/aiffel/E05_SpeechToText/data/speech_wav_8000.npz'\n",
    "speech_data = np.load(data_path)\n",
    "\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wave data shape :  (50620, 8000)\n",
      "Label data shape :  (50620, 1)\n",
      "✅\n"
     ]
    }
   ],
   "source": [
    "print(\"Wave data shape : \", speech_data[\"wav_vals\"].shape)   # data\n",
    "print(\"Label data shape : \", speech_data[\"label_vals\"].shape) #features\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand num :  13911\n",
      "Wave data shape :  (8000,)\n",
      "label :  ['right']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython.display as ipd\n",
    "import random\n",
    "\n",
    "rand = random.randint(0, len(speech_data[\"wav_vals\"])) #데이터를 랜덤하게 선택\n",
    "print(\"rand num : \", rand)\n",
    "\n",
    "sr = 8000   # 1초동안 재생되는 샘플의 갯수. sample rate.\n",
    "data = speech_data[\"wav_vals\"][rand]\n",
    "print(\"Wave data shape : \", data.shape)\n",
    "print(\"label : \", speech_data[\"label_vals\"][rand])\n",
    "\n",
    "ipd.Audio(data, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label data 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL :  ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence']\n",
      "Indexed LABEL :  {'yes': 0, 'no': 1, 'up': 2, 'down': 3, 'left': 4, 'right': 5, 'on': 6, 'off': 7, 'stop': 8, 'go': 9, 'unknown': 10, 'silence': 11}\n"
     ]
    }
   ],
   "source": [
    "target_list = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
    "\n",
    "label_value = target_list\n",
    "label_value.append('unknown')\n",
    "label_value.append('silence')\n",
    "\n",
    "print('LABEL : ', label_value)\n",
    "\n",
    "new_label_value = dict()\n",
    "for i, l in enumerate(label_value):\n",
    "    new_label_value[l] = i\n",
    "label_value = new_label_value\n",
    "\n",
    "print('Indexed LABEL : ', new_label_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  3,  3, ..., 11, 11, 11])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = []\n",
    "\n",
    "# Label data를 int로 바꿔주기\n",
    "for v in speech_data[\"label_vals\"]:\n",
    "    temp.append(label_value[v[0]])\n",
    "label_data = np.array(temp)\n",
    "\n",
    "label_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train, test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.2383825e-04  8.5144420e-04  1.0770605e-03 ... -1.3129720e-03\n",
      "  -1.0830584e-03  1.8275771e-04]\n",
      " [ 3.5200752e-03  5.1622144e-03 -2.6506241e-06 ...  2.8476422e-03\n",
      "   2.4099741e-03 -1.4102276e-03]\n",
      " [ 8.2653237e-04  1.4297181e-03  9.5593289e-04 ...  1.1702370e-03\n",
      "   1.3654147e-03  1.4000607e-03]\n",
      " ...\n",
      " [ 3.5496005e-03  5.1288921e-03  4.3123064e-04 ...  2.6259827e-03\n",
      "   2.4437841e-03 -1.3070083e-03]\n",
      " [-1.1166940e-04 -1.2065521e-04 -2.0386340e-04 ...  5.3304429e-05\n",
      "   7.3213530e-05  1.6120664e-04]\n",
      " [-1.1086896e-02 -1.2538433e-03 -1.2884424e-02 ... -6.7341099e-03\n",
      "  -2.9162155e-02 -5.5060279e-02]]\n",
      "✅\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sr = 8000\n",
    "X_train, X_test, y_train, y_test = train_test_split(speech_data[\"wav_vals\"],\n",
    "                                                   label_data,\n",
    "                                                   test_size=0.1,\n",
    "                                                    shuffle = True)\n",
    "print(X_train)\n",
    "\n",
    "X_train = X_train.reshape([-1,sr,1])  # add channel for CNN\n",
    "X_test = X_test.reshape([-1, sr, 1])\n",
    "\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data :  (45558, 8000, 1)\n",
      "train labels :  (45558,)\n",
      "test data :  (5062, 8000, 1)\n",
      "test labels :  (5062,)\n",
      "✅\n"
     ]
    }
   ],
   "source": [
    "print(\"train data : \", X_train.shape)\n",
    "print(\"train labels : \", y_train.shape)\n",
    "print(\"test data : \", X_test.shape)\n",
    "print(\"test labels : \", y_test.shape)\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습을 위한 하이퍼파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ssac18/aiffel/E05_SpeechToText/models/wav'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "max_epochs = 10\n",
    "\n",
    "# the save point\n",
    "checkpoint_dir = os.getenv('HOME')+'/aiffel/E05_SpeechToText/models/wav'\n",
    "\n",
    "checkpoint_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅\n"
     ]
    }
   ],
   "source": [
    "def one_hot_label(wav, label):\n",
    "    label = tf.one_hot(label, depth=12)\n",
    "    return wav, label\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 8000, 1), (None, 12)), types: (tf.float32, tf.float32)>\n",
      "<BatchDataset shapes: ((None, 8000, 1), (None, 12)), types: (tf.float32, tf.float32)>\n",
      "✅\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# for train\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_dataset = train_dataset.map(one_hot_label)\n",
    "train_dataset = train_dataset.repeat().batch(batch_size=batch_size)\n",
    "print(train_dataset)\n",
    "\n",
    "# for test\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "test_dataset = test_dataset.map(one_hot_label)\n",
    "test_dataset = test_dataset.batch(batch_size=batch_size)\n",
    "print(test_dataset)\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del speech_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2차원 Spectrogram 데이터를 처리하는 모델 구성\n",
    "# 1. 기본 Model ver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        [(None, 8000, 24, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 8000, 24, 32)      320       \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 8000, 24, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 4000, 12, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 4000, 12, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 4000, 12, 64)      18496     \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 4000, 12, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 2000, 6, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 2000, 6, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 2000, 6, 128)      73856     \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 2000, 6, 128)      147584    \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 2000, 6, 128)      147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 1000, 3, 128)      0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 1000, 3, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 1000, 3, 256)      295168    \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 1000, 3, 256)      590080    \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 1000, 3, 256)      590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 500, 1, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 500, 1, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               32768256  \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 12)                3084      \n",
      "=================================================================\n",
      "Total params: 34,681,708\n",
      "Trainable params: 34,681,196\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "input_tensor = layers.Input(shape=(sr, 24, 1))   \n",
    "\n",
    "x = layers.Conv2D(32, (3,3), padding='same', activation='relu')(input_tensor)\n",
    "x = layers.Conv2D(32, (3,3), padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Conv2D(64, (3,3), padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(64, (3,3), padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Conv2D(128, (3,3), padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(128, (3,3), padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(128, (3,3), padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Conv2D(256, (3,3), padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(256, (3,3), padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(256, (3,3), padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "\n",
    "output_tensor = layers.Dense(12)(x)             # 최종 출력은 12차원. 타겟 개수가 12개니까!\n",
    "\n",
    "model_wav = tf.keras.Model(input_tensor, output_tensor)\n",
    "\n",
    "model_wav.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅\n"
     ]
    }
   ],
   "source": [
    "optimizer=tf.keras.optimizers.Adam(1e-4)          # adam optimizer \n",
    "model_wav.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),       # categorical loss\n",
    "             optimizer=optimizer,\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 가중치를 저장\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_dir,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 monitor='val_loss',\n",
    "                                                 mode='auto',\n",
    "                                                 save_best_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_wav = model_wav.fit(train_dataset, epochs=max_epochs,\n",
    "                    steps_per_epoch=len(train_wav) // batch_size,\n",
    "                    validation_data=test_dataset,\n",
    "                    validation_steps=len(test_wav) // batch_size,\n",
    "                    callbacks=[cp_callback]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_wav.history['accuracy']\n",
    "val_acc = history_wav.history['val_accuracy']\n",
    "\n",
    "loss=history_wav.history['loss']\n",
    "val_loss=history_wav.history['val_loss']\n",
    "\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wav.load_weights(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model_wav.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "print(\"loss value: {:.3f}\".format(results[0]))\n",
    "# accuracy\n",
    "print(\"accuracy value: {:.4f}%\".format(results[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_label_value = {v: k for k, v in label_value.items()}\n",
    "batch_index = np.random.choice(len(test_wav), size=1, replace=False)\n",
    "\n",
    "batch_xs = test_wav[batch_index]\n",
    "batch_ys = test_label[batch_index]\n",
    "y_pred_ = model_wav(batch_xs, training=False)\n",
    "\n",
    "print(\"label : \", str(inv_label_value[batch_ys[0]]))\n",
    "\n",
    "ipd.Audio(batch_xs.reshape(8000,), rate=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.argmax(y_pred_) == batch_ys[0]:\n",
    "    print(\"y_pred: \" + str(inv_label_value[np.argmax(y_pred_)]) + '(Correct!)')\n",
    "else:\n",
    "    print(\"y_pred: \" + str(inv_label_value[np.argmax(y_pred_)]) + '(Incorrect!)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Skip Connection Model ver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = layers.Input(shape=(sr, 24, 1))\n",
    "\n",
    "x = layers.Conv1D(32, (3,3), padding='same', activation='relu')(input_tensor)\n",
    "x = layers.Conv1D(32, (3,3), padding='same', activation='relu')(x)\n",
    "skip_1 = layers.MaxPool1D()(x)\n",
    "\n",
    "x = layers.Conv1D(64, (3,3), padding='same', activation='relu')(skip_1)\n",
    "x = layers.Conv1D(64, (3,3), padding='same', activation='relu')(x)\n",
    "x = tf.concat([x, skip_1], -1)\n",
    "skip_2 = layers.MaxPool1D()(x)\n",
    "\n",
    "x = layers.Conv1D(128, (3,3), padding='same', activation='relu')(skip_2)\n",
    "x = layers.Conv1D(128, (3,3), padding='same', activation='relu')(x)\n",
    "x = layers.Conv1D(128, (3,3), padding='same', activation='relu')(x)\n",
    "x = tf.concat([x, skip_2], -1)\n",
    "skip_3 = layers.MaxPool1D()(x)\n",
    "\n",
    "x = layers.Conv1D(256, (3,3), padding='same', activation='relu')(skip_3)\n",
    "x = layers.Conv1D(256, (3,3), padding='same', activation='relu')(x)\n",
    "x = layers.Conv1D(256, (3,3), padding='same', activation='relu')(x)\n",
    "x = tf.concat([x, skip_3], -1)\n",
    "x = layers.MaxPool1D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "\n",
    "output_tensor = layers.Dense(12)(x)\n",
    "\n",
    "model_wav_skip = tf.keras.Model(input_tensor, output_tensor)\n",
    "\n",
    "model_wav_skip.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=tf.keras.optimizers.Adam(1e-4)\n",
    "model_wav_skip.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "             optimizer=optimizer,\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the save point\n",
    "checkpoint_dir = os.getenv('HOME')+'/aiffel/E05_SpeechToText/models/wav_skip'\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_dir,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 monitor='val_loss',\n",
    "                                                 mode='auto',\n",
    "                                                 save_best_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_wav_skip = model_wav_skip.fit(train_dataset, epochs=max_epochs,\n",
    "                    steps_per_epoch=len(train_wav) // batch_size,\n",
    "                    validation_data=test_dataset,\n",
    "                    validation_steps=len(test_wav) // batch_size,\n",
    "                    callbacks=[cp_callback]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_wav_skip.history['accuracy']\n",
    "val_acc = history_wav_skip.history['val_accuracy']\n",
    "\n",
    "loss=history_wav_skip.history['loss']\n",
    "val_loss=history_wav_skip.history['val_loss']\n",
    "\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation \n",
    "model_wav_skip.load_weights(checkpoint_dir)\n",
    "results = model_wav_skip.evaluate(test_dataset)\n",
    "\n",
    "# loss\n",
    "print(\"loss value: {:.3f}\".format(results[0]))\n",
    "# accuracy\n",
    "print(\"accuracy value: {:.4f}%\".format(results[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test \n",
    "\n",
    "inv_label_value = {v: k for k, v in label_value.items()}\n",
    "batch_index = np.random.choice(len(test_wav), size=1, replace=False)\n",
    "\n",
    "batch_xs = test_wav[batch_index]\n",
    "batch_ys = test_label[batch_index]\n",
    "y_pred_ = model_wav_skip(batch_xs, training=False)\n",
    "\n",
    "print(\"label : \", str(inv_label_value[batch_ys[0]]))\n",
    "\n",
    "ipd.Audio(batch_xs.reshape(8000,), rate=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.argmax(y_pred_) == batch_ys[0]:\n",
    "    print(\"y_pred: \" + str(inv_label_value[np.argmax(y_pred_)]) + '(Correct!)')\n",
    "else:\n",
    "    print(\"y_pred: \" + str(inv_label_value[np.argmax(y_pred_)]) + '(Incorrect!)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
